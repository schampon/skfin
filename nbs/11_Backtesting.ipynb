{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we construct a backtest using industry data. More precisely, we use data from Ken French's data library to construct a simple industry momentum return predictor.\n",
    "\n",
    "The goal of a backtest is to assess the validity of a trading predictor at any point in the past. In particular, it is crucial to avoid any forward-looking bias -- in which information available only after time $t$ is mistakingly used at time $t$. In practice, the predictors are estimated over `rolling` (or `expanding`) windows. We implement rolling window estimation with the `sklearn` `TimeSeriesSplit` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For backtesting, visualisation is very important and we make use of some plotting functions introduced in the Appendix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.plot import line, bar, heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry momentum backtest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup for predicting industry returns is the following: \n",
    "\n",
    "- the assets are industries; \n",
    "\n",
    "- the return forecast $\\alpha$ is estimated using rolling-window returns (over $L$ months, $L=12$) preceding a given date; \n",
    "\n",
    "-  no `look-ahead bias`: at each date, only information up that date is used; \n",
    "\n",
    "- such a strategy goes long past \"winners\" (industries with higher-than-average returns) and goes short \"losers\" (industries with lower-than-average returns) $\\Rightarrow$ Momentum strategy; \n",
    "\n",
    "- this strategy is often implemented by skipping the most recent month to avoid the `1-month reversal\" effect`. \n",
    "\n",
    "The article \"Do Industries Explain Momentum\" (1999) by  Moskowitz and Grinblatt  in the  *Journal of Finance* document that indeed there is momentum in industry returns -- past industry returns help predict statistically and economically future industry returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image(\"images/l2_grinblatt_header.png\", width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "display(Image(\"images/l2_grinblatt_table3heading.PNG\", width=600))\n",
    "display(Image(\"images/l2_grinblatt_table3heading2.PNG\", width=800))\n",
    "display(Image(\"images/l2_grinblatt_table3.PNG\", width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Industry data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the data, we use the function `load_kf_returns` introduce in the `Data` section: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.datasets import load_kf_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_data = load_kf_returns(cache_dir=\"data\", force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Moskowitz-Grinblatt paper was published in August 1999, we will keep the data after 1999 as `out-of-sample` and only use the data before 1999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:'1999']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time convention:\n",
    "- holdings $h_t$ and returns $r_t$ are known for period $t$ -- ie. *at the end of period $t$.\n",
    "\n",
    "- so to compute pnl with forward-looking information, the holdings must only depend on information up to $t-1$\n",
    "\n",
    "- in practice, we will have\n",
    "\n",
    "$$ pnl_t = h_{t-1} \\times r_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Backtesting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next set of helper file, we introduce the main `Bactester` class and the `fit_and_predict` function to run rolling window estimations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%writefile ../skfin/backtesting.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils.metaestimators import _safe_split\n",
    "\n",
    "\n",
    "class Backtester:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        ret,\n",
    "        max_train_size=36,\n",
    "        test_size=1,\n",
    "        start_date=\"1945-01-01\",\n",
    "        end_date=None,\n",
    "    ):\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.estimator = estimator\n",
    "        self.ret = ret[: self.end_date]\n",
    "        self.cv = TimeSeriesSplit(\n",
    "            max_train_size=max_train_size,\n",
    "            test_size=test_size,\n",
    "            n_splits=1 + len(ret.loc[start_date:end_date]) // test_size,\n",
    "        )\n",
    "\n",
    "    def train(self, features, target):\n",
    "        pred, estimators = fit_predict(\n",
    "            self.estimator, features, target, self.ret, self.cv, return_estimator=True\n",
    "        )\n",
    "        self.estimators_ = estimators\n",
    "        self.h_ = pred\n",
    "        if isinstance(pred, pd.DataFrame):\n",
    "            self.pnl_ = (\n",
    "                pred.shift(1).mul(self.ret).sum(axis=1)[self.start_date : self.end_date]\n",
    "            )\n",
    "        elif isinstance(pred, pd.Series):\n",
    "            self.pnl_ = pred.shift(1).mul(self.ret)[self.start_date : self.end_date]\n",
    "        return self\n",
    "\n",
    "\n",
    "def _fit_predict(estimator, X, y, train, test, return_estimator=False):\n",
    "    X_train, y_train = _safe_split(estimator, X, y, train)\n",
    "    X_test, _ = _safe_split(estimator, X, y, test, train)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    if return_estimator:\n",
    "        return estimator.predict(X_test), estimator\n",
    "    else:\n",
    "        return estimator.predict(X_test)\n",
    "\n",
    "\n",
    "def fit_predict(\n",
    "    estimator,\n",
    "    features,\n",
    "    target,\n",
    "    ret,\n",
    "    cv,\n",
    "    return_estimator=False,\n",
    "    verbose=0,\n",
    "    pre_dispatch=\"2*n_jobs\",\n",
    "    n_jobs=1,\n",
    "):\n",
    "    parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n",
    "    res = parallel(\n",
    "        delayed(_fit_predict)(\n",
    "            clone(estimator), features, target, train, test, return_estimator\n",
    "        )\n",
    "        for train, test in cv.split(ret)\n",
    "    )\n",
    "    if return_estimator:\n",
    "        pred, estimators = zip(*res)\n",
    "    else:\n",
    "        pred = res\n",
    "\n",
    "    idx = ret.index[np.concatenate([test for _, test in cv.split(ret)])]\n",
    "    if isinstance(ret, pd.DataFrame):\n",
    "        cols = ret.columns\n",
    "        df = pd.DataFrame(np.concatenate(pred), index=idx, columns=cols)\n",
    "    elif isinstance(ret, pd.Series):\n",
    "        df = pd.Series(np.concatenate(pred), index=idx)\n",
    "    else:\n",
    "        df = None\n",
    "\n",
    "    if return_estimator:\n",
    "        return df, estimators\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.mv_estimators import MeanVariance\n",
    "from skfin.backtesting import Backtester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the data is monthly, we re-estimate the model every month. This is done by choosing the parameter `n_splits` in the class `TimeSeriesSplit` as the number of months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"1945-01-01\"\n",
    "test_size = 1\n",
    "params = dict(max_train_size=36, test_size=test_size, gap=0)\n",
    "params[\"n_splits\"] = 1 + len(ret.loc[start_date:]) // test_size\n",
    "\n",
    "cv = TimeSeriesSplit(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely, with `TimeSeriesSplit`:\n",
    "\n",
    "- the `test` indices are the dates for which the holdings are computed.\n",
    "\n",
    "- the `train` indices are the date range over which a forecasting model is trained.\n",
    "\n",
    "- the target will been shifted by $-1$ and `gap` is set to 0. \n",
    "\n",
    "- we can estimate batches with `test_size` > 1.\n",
    "\n",
    "- `n_splits` is determined so that the backtest starts (just) before a certain start date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in cv.split(ret):\n",
    "    break\n",
    "ret.iloc[train].index[-1].strftime('%Y%m%d'), ret.iloc[test].index[0].strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Empiricial results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Cumulative pnl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define two transform functions: \n",
    "\n",
    "- `transform_X` computes the main feature  (or `predictor`) as the average of the trailing 12-month returns; \n",
    "- `transform_y` is applied on the returns -- here when passed to the mean-variance `MeanVariance` class to compute the covariance matrix; but more generally to serve as a target for predictors with machine-learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_X = lambda x: x.rolling(12).mean().values\n",
    "transform_y = lambda x: x.shift(-1).values\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_h = []\n",
    "for train, test in cv.split(ret): \n",
    "    m = MeanVariance()\n",
    "    m.fit(features[train], target[train])\n",
    "    _h += [m.predict(features[test])]\n",
    "    \n",
    "cols = ret.columns \n",
    "idx = ret.index[np.concatenate([test for _, test in cv.split(ret)])]\n",
    "h = pd.DataFrame(np.concatenate(_h), index=idx, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `line` plotting function shows the sharpe ratio \"sr\" of the strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl = h.shift(1).mul(ret).sum(axis=1)[start_date:]\n",
    "line(pnl.rename('Industry momentum'), cumsum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `Backtester` class and we test that the two approaches yield the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backtester(estimator=MeanVariance(), ret=ret)\n",
    "m.train(features, target)\n",
    "h.equals(m.h_), pnl.equals(m.pnl_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Other backtest statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract information for the estimator -- e.g. in this simple case, recover the covariance matrix fitted by the class `MeanVariance()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = m.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_mean = pd.DataFrame(sum([m.V_ for m in estimators])/len(estimators), ret.columns, ret.columns)\n",
    "heatmap(V_mean, title='Average covariance matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backtester(estimator=MeanVariance(), ret=ret)\n",
    "pnls = {}\n",
    "for window in [6, 12, 24, 36]: \n",
    "    features_ = ret.rolling(window).mean().values\n",
    "    m.train(features_, target)\n",
    "    pnls[window] = m.pnl_\n",
    "line(pnls, cumsum=True, start_date='1945', title='Cumulative pnl for different look-back windows (in month)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph shows the `lead-lag sharpe ratio` plot for the industry momentum backtest: \n",
    "    \n",
    "- the horizon \"0\" (green bar) represents the sharpe ratio of the tradable pnl; \n",
    "- the lagged horizons (with positive coordinates) show the performance when the positions are lagged by several months and illustrates the `alpha decay` of the predictor; \n",
    "- the lead horizons (with negative coordinates) represent the non-tradable counterfactual performance if the information had been available earlier. \n",
    "\n",
    "For `trending` predictors (like the industry momentum backtest), the lead sharpe ratios are very high and the alpha decay is quite fast. For `contrarian` predictors, the lead sharpe ratios are negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.metrics import sharpe_ratio\n",
    "sr = {i: h.shift(1+i).mul(ret).sum(axis=1).pipe(sharpe_ratio) for i in range(-10, 12)}\n",
    "bar(sr, baseline=0, sort=False, title='Lead-lag sharpe ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `off-the-top` approach is to remove an asset from the tradable set and check whether the portfolio sharpe ratio decreases (in which case, this asset is a *contributor*) or increases (in which case, this asset is a *detractor*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnls_ott = {}\n",
    "for c in ret.columns:\n",
    "    ret_ = ret.drop(c, axis=1)\n",
    "    features_ = transform_X(ret_)\n",
    "    target_ = transform_y(ret_)\n",
    "    pnl_ = Backtester(estimator=MeanVariance(), ret=ret_).train(features_, target_).pnl_\n",
    "    pnls_ott[c] = pnl_.pipe(sharpe_ratio)\n",
    "\n",
    "pnls_ott[\"ALL\"] = pnl.pipe(sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(pnls_ott, baseline=\"ALL\", title='Industry momentum off-the-top')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
