{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "274d4369",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b561007",
   "metadata": {},
   "source": [
    "## What hedge funds do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41c986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.893081Z",
     "iopub.status.busy": "2023-12-07T08:12:07.892601Z",
     "iopub.status.idle": "2023-12-07T08:12:07.902405Z",
     "shell.execute_reply": "2023-12-07T08:12:07.901733Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985c66b",
   "metadata": {},
   "source": [
    "This material is an introduction to using machine-learning for portfolio management and trading. Given the centrality of programming in hedge funds today, the concepts are exposed using only `jupyter` notebooks in `python`. Moreover, we leverage the `scikit-learn` package (also known as `sklearn`) to illustrate how machine-learning is used in practice in this context. \n",
    "\n",
    "As shown by the illustration below, we cover here topics that span Finance (market microstructure, portfolio construction, data, etc), Machine-learning (including mathematics and statistics) and Software engineering/Computer science. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76a5aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.905453Z",
     "iopub.status.busy": "2023-12-07T08:12:07.905047Z",
     "iopub.status.idle": "2023-12-07T08:12:07.927691Z",
     "shell.execute_reply": "2023-12-07T08:12:07.927011Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/ml_triangle.png\", width=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ee365",
   "metadata": {},
   "source": [
    "We are interested in how quantitative hedge funds operate in practice. Today, quantitative hedge funds are essentially *consumers* of data -- they ingest all sorts of datasets and extract information used to systematically buy or sell securities. Researchers and portfolio managers are deeply involved in the process of `data ingestion` and `information extraction`, but they do not directly decide which securities are bought or sold -- instead algorithms do.\n",
    "\n",
    "Because these processes of `data ingestion` and `information extraction` are so central to quantitative hedge fund operations, they have become `software companies` -- a lot of the intellectual property (IP) of hedge funds is embedded in the code they write. And in that sense, hedge funds are not so different from other data-science based technology companies. (And in fact the hiring has become very similar, with a lot of interest in profiles out of Computer Science, Machine-Learning, Data engeeniring, Statistics, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534a64d",
   "metadata": {},
   "source": [
    "Another point is the Hedge Fund industry is very competitive and given that the frontier of knowledge is today moving very quickly (because of active research in Data, ML, hardware, software, etc) not keeping up with progress runs the risk of lagging by the competition. More precisely, innovation implies comming up with new ideas, testing them, deploying these ideas in trading systems; learning from them -- and then deploying newer ideas after that. Of course, this kind of \"loop of progress\" (see [Francois Chollet (04/03/2019)](https://twitter.com/fchollet/status/1113476428249464833)) is common to all AI-impacted industries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390cc32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.930846Z",
     "iopub.status.busy": "2023-12-07T08:12:07.930441Z",
     "iopub.status.idle": "2023-12-07T08:12:07.954113Z",
     "shell.execute_reply": "2023-12-07T08:12:07.953433Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/kaggle_iterations2.png\", width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29394d61",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d13dc8",
   "metadata": {},
   "source": [
    "Across notebooks, we cover three main empirical use-cases: timing industry returns; timing stock returns; and timing the market (ie. timing the Standard and Poor's 500 index). For each use-case, there is a set of toy-datasets (described in the `Data` section).\n",
    "\n",
    "Moreover: \n",
    "\n",
    "- for the industry return backtest, we illustrate several main concepts: learning (with linear models, boosted trees, and MLP neural nets); risk; factor exposures; transaction costs; ensemble; \n",
    "- for the stock return backtest, we illustrate mean-reversion, trading around corporate events and sentiment (in earning calls); \n",
    "- for the market timing backtest, we also illustrate traing around macroeconomic events, and extracting sentiment in the statements of the Federal Open Market Committee (FOMC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c2f4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.959738Z",
     "iopub.status.busy": "2023-12-07T08:12:07.959304Z",
     "iopub.status.idle": "2023-12-07T08:12:07.967180Z",
     "shell.execute_reply": "2023-12-07T08:12:07.966514Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/book_overview2.png\", width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34956895",
   "metadata": {},
   "source": [
    "## Quant workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72b0ea",
   "metadata": {},
   "source": [
    "The graph below shows the typical data workflow of a quantitative fund: \n",
    "\n",
    "- Raw data is acquired generally by a Data team and possibly transformed into usable features. \n",
    "- Data quality is checked, in particular that timestamp of each observation is valid and has not been revised in a way that injects future information. \n",
    "- From these features, predictors of asset returns are derived. \n",
    "- Given a single predictor (or a set of many predictors), porfolios are constructed: these portfolios represent the ideal positions of a fund given the asset forecasts, but also risk forecasts (and possibly, transaction cost forecasts). \n",
    "- When these ideal positions change from one day to the next (because the underlying data has been updated), the difference in positions initiate trades that are then executed on asset exchanges or with brokers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9ad30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.970283Z",
     "iopub.status.busy": "2023-12-07T08:12:07.969893Z",
     "iopub.status.idle": "2023-12-07T08:12:07.984857Z",
     "shell.execute_reply": "2023-12-07T08:12:07.984202Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/quant_workflow.png\", width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5564f9c",
   "metadata": {},
   "source": [
    "##Â MLOps for backtests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7769c",
   "metadata": {},
   "source": [
    "MLOps (machine learning operations) represents a set of practices for the deployment of ML models in production. For quant hedge funds, there are two main concepts that we describe here:  \n",
    "\n",
    "- pipelines \n",
    "\n",
    "- backtests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a165062",
   "metadata": {},
   "source": [
    "### Pipelines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40db95d6",
   "metadata": {},
   "source": [
    "Pipeline: \n",
    "\n",
    "> A machine-learning pipeline is an end-to-end description of the automated flow of data from raw inputs to a desired output. Each step represents a transformation of the data, possibly with a fitted model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ddd649",
   "metadata": {},
   "source": [
    "The diagram below illustrates a pipeline for a quant fund. The end point (to the right of the diagram) are the positions or `holdings` in a set of traded securities -- and combined with the returns on these securities, the pnl of a given strategy can be computed. The entry point (to the left of the diagram) are `features`. A set of `transformations` (pre-determined in the `pipeline`) are applied to these `features` to produce the desired `holdings`. Some `transformations` in the `pipeline` are \"fixed\" while others depend on `fitted models` (e.g. a ML predictor of returns or a risk model). \n",
    "\n",
    "In the diagram, we emphasize the timing of these different objects: \n",
    "\n",
    "- for a pnl at time $t$, the `features` and `target` include only information up to $t-1$ so that the holdings are known in $t-1$ and can accrue returns over the period $t$. \n",
    "\n",
    "The following equation summarizes this point: \n",
    "\n",
    "$$ pnl_t = holdings_{t-1} \\times returns_t. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b06776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.988466Z",
     "iopub.status.busy": "2023-12-07T08:12:07.988035Z",
     "iopub.status.idle": "2023-12-07T08:12:07.996047Z",
     "shell.execute_reply": "2023-12-07T08:12:07.995382Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/ml4pmt_pipeline3.png\", width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada2ab9",
   "metadata": {},
   "source": [
    "###Â Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10b0d3",
   "metadata": {},
   "source": [
    "The following notebooks and notes are largely based on  `scikit-learn`. `scikit-learn` is an extremely powerful (and widely used) package for machine-learning. In particular, it provides a \"grammar\" for pipelines  where each transformation or estimator class has the `fit`/`transform`/`predict` functions with arguments as (`X`, `y`) where `X` represents the  features and `y`, targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e9ae6",
   "metadata": {},
   "source": [
    "A look-ahead bias occurs when data dated at $t$ includes information only available after $t$; in contrast, point-in-time data ensures that data dated at t is based on only information up to date t. A backtest is a method to simulate a strategy using point-in-time historical data and evaluate its profitability. \n",
    "\n",
    "In order to illustrate how to use pipelines Ã  la `scikit-learn` for quantitative portfolio management, we introduce in the next sections two objects: \n",
    "\n",
    "- a `Mean-variance` estimator that computes positions from a predictor;\n",
    "- a `Backtester` class that fits a `scikit-learn` estimator over rolling windows (as defined by the `TimeSeriesSplit` class). \n",
    "\n",
    "The `Backtester` class runs the rolling window simulation so that only information up to date $t-1$ is used to determined the holdings at that date. The following graph shows an example of a learning pipeline (with a `StandardScaler` and `Ridge` steps before compute the positions with the `Mean-variance` estimator) that we will use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd679ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:07.999328Z",
     "iopub.status.busy": "2023-12-07T08:12:07.998915Z",
     "iopub.status.idle": "2023-12-07T08:12:08.005282Z",
     "shell.execute_reply": "2023-12-07T08:12:08.004616Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/ml_pipeline_example.png\", width=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8d745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:08.008128Z",
     "iopub.status.busy": "2023-12-07T08:12:08.007744Z",
     "iopub.status.idle": "2023-12-07T08:12:12.982911Z",
     "shell.execute_reply": "2023-12-07T08:12:12.982171Z"
    }
   },
   "outputs": [],
   "source": [
    "from skfin import Backtester, MeanVariance, Ridge\n",
    "from skfin.datasets import load_kf_returns\n",
    "from skfin.plot import line\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "estimator = make_pipeline(StandardScaler(with_mean=False), Ridge(), MeanVariance())\n",
    "\n",
    "returns_data = load_kf_returns(cache_dir=\"data\")\n",
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:\"1999\"]\n",
    "\n",
    "transform_X = lambda x: x.rolling(12).mean().fillna(0)\n",
    "transform_y = lambda x: x.shift(-1)\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)\n",
    "\n",
    "pnl_ = Backtester(estimator).train(features, target, ret)\n",
    "line(pnl_, cumsum=True, title=\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeda970-e50f-4cd1-9e0e-9d954da60fdc",
   "metadata": {},
   "source": [
    "The graph above shows the annualized sharpe ratio (as `sr`): given that the strategy is monthly, this is the montly pnl average divided by the monthly pnl standard deviation and \"annualized\" by multiplying by the square-root of the number of observation per year ($\\sqrt{12}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7275c5dc",
   "metadata": {},
   "source": [
    "## Python package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a99cc2",
   "metadata": {},
   "source": [
    "All the classes and functions used across notebooks are stored in `.py` files using the `jupyter magic`: `%%writefile`. And these files are structured as a repository on `github` that can be cloned from the command line (once in the correct directory):  \n",
    "> ```git clone https://github.com/schampon/skfin.git && cd skfin```\n",
    "\n",
    "The following script helps create an environment with the proper packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5053252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:12:12.986499Z",
     "iopub.status.busy": "2023-12-07T08:12:12.986216Z",
     "iopub.status.idle": "2023-12-07T08:12:12.998257Z",
     "shell.execute_reply": "2023-12-07T08:12:12.997599Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ../create_env.sh\n",
    "conda create python=3.9 --name  skfin -c https://conda.anaconda.org/conda-forge/ -y\n",
    "conda activate skfin\n",
    "\n",
    "pip install -r requirements.txt\n",
    "pip install -e . \n",
    "python -m ipykernel install --user --name skfin --display-name \"Python (skfin)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b719ea",
   "metadata": {},
   "source": [
    "In practice, this is done from the command line with: \n",
    "    \n",
    "> ``` ./create_env.sh ```"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
