{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order book and trades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we discuss the cost associated trading following Section 3.7 in *Engineering Investment Process* by Ielpo, Merhy and Simon (2017). A rule of thumbs is \n",
    "\n",
    "> \"It takes one day of volume to trade one day of volatility.\"\n",
    "\n",
    "In other words: *the bigger trade, the higher the cost*. \n",
    "\n",
    "There are three main categories of trade execution: \n",
    "\n",
    "1. over-the-counter (OTC): the price of the transaction is directly negotiated with another market participant; \n",
    "\n",
    "1. delegated-execution: the trade is delegated to a broker with a guarantee of execution price (e.g. price at close or volume-weighted average price as VWAP). \n",
    "\n",
    "1. direct trade and execution on markets. \n",
    "\n",
    "There is a tradeoff between trading immediately at a known (and potentially high) price and trading later, but at an unknown time/date and for an unknown price. In this context, there are two different types of costs: \n",
    "\n",
    "- direct/explicit costs: commissions, brokerage fees, settlement/clearing fees, exchange fees, taxes. This also includes shorting costs with easy-to-borrow / hard-to-borrow rates. \n",
    "\n",
    "- indirect/implicit/impact costs: loosely, these costs capture the idea that the bigger the trade, the higher the cost. But typically, each investor faces impact costs depending on execution choice, execution pattern, latency, procedure speed and horizon. These impact costs are estimated based on (potentially private) past trades. \n",
    "\n",
    "At any given point in time, some market participants can make public their willingness to trade a quantity at a given price in an *order book*. More precisely, an order book refers to an electronic list of buy and sell orders for a specific security or financial instrument organized by price level.\n",
    "\n",
    "The bid-ask spread is the difference between the highest price that a buyer is willing to pay for an asset and the lowest price that a seller is willing to accept. More precisely, there are two types of orders: \n",
    "\n",
    "1. market order: this is an instruction by an investor to a broker to buy or sell an assets at the best available price in the order book. \n",
    "\n",
    "1. limit order: this is an instruction to a broker to buy or sell only a certain quantity at a certain price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positions and turnover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous section, the positions $h_t$ have been rescaled so that \n",
    "\n",
    "$$ \\sqrt{h_t^T V_t h_t} = 1$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ \\sum_t h_{n, t} = 0.$$\n",
    "\n",
    "More generally the positions are denominated in dollars as: \n",
    "\n",
    "$$pos_t = \\theta \\times h_t, $$ \n",
    "\n",
    "where the scaler is a risk target in dollars:  $\\theta = \\sqrt{pos_t^T V_t pos_t}.$ Given this risk target, the (two-sided) gross  leverage \n",
    "$$ \\text {Leverage} = \\sum_{n} | pos_{n,t}|$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From (rescaled) positions in asset $n$ are denoted $h_{n, t}$, the trades *quantities* are: \n",
    "    \n",
    "$$ q_{n, t}  = pos_{n, t} - (1+r_t) pos_{n, t-1}.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (One-sided) turnover \n",
    "$$ \\text {TrueTurnover}_t = \\sum_{n} | pos_{n,t} - (1+r_{t}) pos_{n,t-1} |/2$$\n",
    "where $h_{n,t} - (1+r_{n,t}) h_{n,t-1}$ is the trade. In most of what we do, approximating the small returns away is good enough: \n",
    "\n",
    "$$ \\text {Turnover}_t = \\sum_{n} | pos_{n,t} - pos_{n,t-1} |/2 $$ \n",
    "\n",
    "- Holding period \n",
    "$$  \\text {HP} = \\frac{\\frac{1}{T} \\sum_{t=1}^T \\text {Leverage}_t}{\\frac{1}{T} \\sum_{t=1}^T\\text{Turnover}_t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below is from Ielpo et al. (2017, p. 239): \n",
    "\n",
    "- $p_0$: decision price \n",
    "\n",
    "- $p_T$: final price \n",
    "\n",
    "- $p_e$: average executing price \n",
    "\n",
    "- $p_{\\infty}$: after the trade, the price reverts to a limit value\n",
    "\n",
    "- $\\text{slippage} = \\frac{p_e}{p_0} -1$ \n",
    "\n",
    "- $\\text{permanent impact} = \\frac{p_{\\infty}}{p_0} -1$\n",
    "\n",
    "Given that trades are motivated by a view of the market (ie. some alpha opportunity), it is difficult to distinguish alpha et pure impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "func1= lambda x:  1 - np.exp(- 10 * x)\n",
    "inv_func1 = lambda y: - np.log(1-y)/10\n",
    "func2 = lambda x: .8*(1 - np.exp(-20 * x))\n",
    "\n",
    "a = .5\n",
    "b = .5\n",
    "#c = 1\n",
    "#c2 = 2.5\n",
    "d = .0025\n",
    "\n",
    "x1 = np.arange(0, a+.001, d)\n",
    "x2 = np.arange(a, 1, d)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "ax.plot(x1, func1(x1))\n",
    "ax.plot(x2, func1(a) - b * func2(x2-a), color='tab:blue')\n",
    "ax.plot([0, 1], [.6-.005, .6 -.005], color='tab:red', linestyle='dashed', linewidth=1)\n",
    "ax.plot([0, 1], [1, 1], color='tab:red', linestyle='dashed', linewidth=1)\n",
    "ax.plot([.5, .5], [0, 1], color='tab:red', linestyle='dashed', linewidth=1)\n",
    "ax.plot([0, inv_func1(.9)], [.9, .9], color='tab:red', linestyle='dashed', linewidth=1)\n",
    "ax.set_yticks([0,.1, .2,.3,.4, .5, .6,.7,.8, .9, 1])\n",
    "ax.set_yticklabels(['$p_0$','', '', '', '', '','$p_\\infty$',  '', '','$p_e$', '$p_T$'], rotation=0);\n",
    "ax.set_xlim([0, 1.25])\n",
    "ax.set_xticks([0,.25, .5,.75, 1, 1.25])\n",
    "ax.set_xticklabels(['$t=0$','', '$t=T$', '', '', 'Time $t$'], rotation=0)\n",
    "plt.arrow(x=1, y=1, dx=0, dy=-.4, head_width=0.02, head_length=0.02,color=\"tab:blue\", length_includes_head = True)\n",
    "plt.annotate('Impact decay',xy=(1, .8), xytext=(10, -10), textcoords='offset points')\n",
    "plt.arrow(x=1, y=0, dx=0, dy=.6, head_width=0.02, head_length=0.02,color=\"tab:blue\", length_includes_head = True)\n",
    "plt.annotate('Permanent decay',xy=(1, .3), xytext=(10, -10), textcoords='offset points')\n",
    "plt.arrow(x=inv_func1(.9), y=0, dx=0, dy=.9, head_width=0.02, head_length=0.02,color=\"tab:blue\", length_includes_head = True)\n",
    "plt.annotate('Slippage',xy=(inv_func1(.9), .3), xytext=(10, -10), textcoords='offset points')\n",
    "ax.set_title('Illustration of the price impact of a small order ($t=0$: trading starts, $t=T$: trading ends)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we define the impact cost as a function $I$: \n",
    "\n",
    "$$ Q \\mapsto I(Q), $$\n",
    "\n",
    "where $Q$ is the traded quantities. The price impact in dollars of trading the quantity $Q$ is \n",
    "\n",
    "$$\\text{ImpactCost} = Q \\times I(Q).$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of traded volume is $\\delta = \\frac{Q_{n, t}}{\\text{Liquidity}_{n, t}}$ can be interpreted as time -- e.g. how many days (or fraction of a day) to trade $Q_{n, t}$ given the asset liquidity $\\text{Liquidity}_{n, t}$. Over that period, the asset volatility scaled in $\\sigma_{n, t} \\sqrt{\\delta}$, so that a simple impact model is: \n",
    "\n",
    "$$ I(Q) = \\sigma \\sqrt{\\frac{Q}{\\text{Liquidity}}}.$$\n",
    "\n",
    "More generally, two parameters $\\langle \\gamma, \\beta \\rangle$ are fitted with the functional form: \n",
    "\n",
    "$$ I(Q) = \\gamma \\sigma \\left(\\frac{Q}{\\text{Liquidity}}\\right)^{\\beta}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rule of thumb is as follows: \n",
    "\n",
    "- for small horizons, $\\beta \\approx 0$, $I(Q)$ is constant (e.g. bid-ask spread) and the total cost is linear; \n",
    "\n",
    "- for long horizons, $\\beta \\approx 1$ and the total impact cost $Q \\times I(Q)$ is quadratic.\n",
    "\n",
    "In  analytically more complex (and potentially more realistic) setups, $\\beta$ is taken to be $1/2$ as motivated above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we focus on quadratic impact cost with $\\beta=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Mean-variance optimisation with quadratic costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With quadratic cost, the mean-variance optimisation can be solved in closed form. More precisely, the mean-variance utility at time $t$ with transaction cost is  \n",
    "$$h_t^T \\alpha - \\frac{h_t V h_t}{2 \\lambda} - \\frac{(h_t - h_{t-1})^T \\Lambda (h_t - h_{t-1})}{2}$$\n",
    "\n",
    "**Lemma**.  Given the mean-variance utility with quadratic cost, the optimal portfolio is \n",
    "\n",
    "$$h_t  = \\left[\\frac{V}{\\lambda} + \\Lambda \\right]^{-1}(\\alpha + \\Lambda h_{t-1}).$$\n",
    "\n",
    "*Proof*. The mean-variance objective is rewritten as \n",
    "$$ h_t^T (\\alpha + \\Lambda h_{t-1}) - \\frac{h_t (V + \\lambda \\Lambda) h_t}{2 \\lambda} - \\frac{h_{t-1}^T \\Lambda h_{t-1}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal portfolio with transaction cost is a weighted average of two holdings: \n",
    "$$h_t  = (I  + \\lambda V^{-1}\\Lambda)^{-1}\\lambda V^{-1}\\alpha + [I -  (I  + \\lambda V^{-1}\\Lambda)^{-1}] h_{t-1}.$$\n",
    "\n",
    "Interpretation: \n",
    "\n",
    "-  the friction-less mean-variance portfolio $\\lambda V^{-1}\\alpha$ is the target portfolio \n",
    "\n",
    "- the optimal portfolio $h_t$ is a weighted-average of this target portfolio and the past holdings $h_{t-1}$: \n",
    "\n",
    "- ideally the investor would like to hold the target portfolio but because of transaction cost, it only trades partially towards this target. \n",
    "\n",
    "-  when the transaction costs are lower and the risk-tolerance $\\lambda$ is higher, the investor loads more on the mean-variance target $\\lambda V^{-1}\\alpha$\n",
    "\n",
    "- the transaction imply so form of (non-linear) exponential averaging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost for the Industry Momentum backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.plot import line, bar\n",
    "from skfin.datasets import load_kf_returns\n",
    "from skfin.mv_estimators import MeanVariance \n",
    "from skfin.backtesting import Backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_data = load_kf_returns(cache_dir='data')\n",
    "ret = returns_data['Monthly']['Average_Value_Weighted_Returns'][:'1999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_X = lambda x: x.rolling(12).mean().values\n",
    "transform_y = lambda x: x.shift(-1).values\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the data is monthly, we re-estimate the model every month and the maximum train window is 12 months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_ = {'constant risk (baseline)': MeanVariance(constant_risk=True), \n",
    "               'variable risk': MeanVariance(constant_risk=False)}\n",
    "line({k: Backtester(v, ret).train(features, target).pnl_ for k, v in estimators_.items()}, \n",
    "     cumsum=True, title='Industry momentum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leverage and turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = Backtester(MeanVariance(constant_risk=False), ret).train(features, target)\n",
    "line(m0.h_.abs().sum(axis=1).rename('leverage'), title='Industry momentum: leverage', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_holding_period(h): \n",
    "    h = h.squeeze()\n",
    "    if isinstance(h, pd.Series):\n",
    "        return h.abs().mean()/h.diff().abs().div(2).mean()\n",
    "    else: \n",
    "        return h.abs().sum(axis=1).mean()/h.diff().abs().sum(axis=1).div(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp =  average_holding_period(m0.h_)\n",
    "\n",
    "print(f'The average holding period is {hp:.2f} months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liquidity and market cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we do not have data on sector liquidity, we use the market capitalisation as a proxy for liquidity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcap = returns_data['Monthly']['Average_Firm_Size']\\\n",
    "        .mul(returns_data['Monthly']['Number_of_Firms_in_Portfolios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line(mcap.loc['1998':].sum(axis=1).div(1e3), \n",
    "     title='Total market cap in $bn (as computed by Ken French)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1/20\n",
    "mcap_norm = mcap.div(mcap.sum(axis=1), axis=0)\n",
    "vol_liquidity_factor = .5 *  gamma * ret.rolling(12).std().div(mcap_norm.loc[ret.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line(vol_liquidity_factor, yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark-to-market and backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, $\\Lambda$ is the diagonal of the vector of return standard deviations over market capitalisation (as a proxy for liquity -- e.g. traded volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../skfin/backtesting_with_cost.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "\n",
    "def compute_pnl_components(h, ret, vol_liquidity_factor=None): \n",
    "    ret = ret[h.index[0]:h.index[-1]]\n",
    "    vol_liquidity_factor = vol_liquidity_factor.loc[h.index[0]:h.index[-1]]\n",
    "    \n",
    "    pnl = h.shift(1).mul(ret).sum(axis=1)\n",
    "    if vol_liquidity_factor is not None: \n",
    "        impact_cost = h.diff().pow(2).mul(vol_liquidity_factor).sum(axis=1)\n",
    "        return {'gross': pnl, \n",
    "                'net = gross - impact cost': pnl.sub(impact_cost), \n",
    "                'impact cost': -1 * impact_cost}\n",
    "    else: \n",
    "        return pnl \n",
    "    \n",
    "\n",
    "def compute_batch_holdings_(pred, V, A=None, past_h=None, vol_liquidity_factor=None, lambda_=None):\n",
    "    \"\"\"\n",
    "    compute markowitz holdings with return prediction \"mu\" and covariance matrix \"V\"\n",
    "\n",
    "    mu: numpy array (shape N * K)\n",
    "    V: numpy array (N * N)\n",
    "\n",
    "    \"\"\"\n",
    "    if (lambda_ is None)&(vol_liquidity_factor is not None): \n",
    "        lambda_ = 1 \n",
    "    N, _ = V.shape\n",
    "    if isinstance(pred, pd.Series) | isinstance(pred, pd.DataFrame):\n",
    "        pred = pred.values\n",
    "    if pred.shape == (N,):\n",
    "        pred = pred[:, None]\n",
    "    elif pred.shape[1] == N:\n",
    "        pred = pred.T\n",
    "        \n",
    "    if (vol_liquidity_factor is not None): \n",
    "        invV = np.linalg.inv(V / lambda_ + 2* np.diag(vol_liquidity_factor))\n",
    "    else: \n",
    "        invV = np.linalg.inv(V)\n",
    "    if A is None:\n",
    "        M = invV\n",
    "    else:\n",
    "        U = invV.dot(A)\n",
    "        if A.ndim == 1:\n",
    "            M = invV - np.outer(U, U.T) / U.dot(A)\n",
    "        else:\n",
    "            M = invV - U.dot(np.linalg.inv(U.T.dot(A)).dot(U.T))\n",
    "    if (vol_liquidity_factor is not None)&(past_h is not None): \n",
    "        h = M.dot(pred + 2 * np.diag(vol_liquidity_factor).dot(past_h.T))\n",
    "    else: \n",
    "        h = M.dot(pred)        \n",
    "    return h.T\n",
    "\n",
    "\n",
    "class MeanVarianceWithCost(BaseEstimator):\n",
    "    def __init__(self, transform_V=None, A=None):\n",
    "\n",
    "        if transform_V is None:\n",
    "            self.transform_V = lambda x: np.cov(x.T)\n",
    "        else:\n",
    "            self.transform_V = transform_V\n",
    "        self.A = A\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.V_ = self.transform_V(y)\n",
    "\n",
    "    def predict(self, X, past_h=None, vol_liquidity_factor=None):\n",
    "        if self.A is None:\n",
    "            T, N = X.shape\n",
    "            A = np.ones(N)\n",
    "        else:\n",
    "            A = self.A\n",
    "        h = compute_batch_holdings_(X, self.V_, A, past_h=past_h, vol_liquidity_factor=vol_liquidity_factor)\n",
    "        return h\n",
    "    \n",
    "class BacktesterWithCost:\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimator,\n",
    "        ret,\n",
    "        vol_liquidity_factor = None, \n",
    "        max_train_size=36,\n",
    "        test_size=1,\n",
    "        start_date=\"1945-01-01\",\n",
    "        end_date=None,\n",
    "        h_init = None, \n",
    "        return_pnl_component=False \n",
    "    ):\n",
    "\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.estimator = estimator\n",
    "        self.ret = ret[: self.end_date]\n",
    "        self.cv = TimeSeriesSplit(\n",
    "            max_train_size=max_train_size,\n",
    "            test_size=test_size,\n",
    "            n_splits=1 + len(ret.loc[start_date:end_date]) // test_size,\n",
    "        )\n",
    "        self.h_init = h_init\n",
    "        self.vol_liquidity_factor = vol_liquidity_factor\n",
    "        self.return_pnl_component = return_pnl_component\n",
    "\n",
    "    def train(self, features, target):\n",
    "        _h = []\n",
    "        past_h = self.h_init  \n",
    "        for train, test in self.cv.split(self.ret): \n",
    "            m = clone(self.estimator)\n",
    "            m.fit(features[train], target[train])\n",
    "            if self.vol_liquidity_factor is None: \n",
    "                vlf = None\n",
    "            else: \n",
    "                vlf = np.squeeze(self.vol_liquidity_factor.values[test])            \n",
    "            current_h = m.predict(features[test], past_h=past_h, vol_liquidity_factor=vlf)\n",
    "            _h += [current_h]\n",
    "            past_h = current_h \n",
    "\n",
    "        cols = self.ret.columns \n",
    "        idx = self.ret.index[np.concatenate([test for _, test in self.cv.split(self.ret)])]\n",
    "        h_ = pd.DataFrame(np.concatenate(_h), index=idx, columns=cols)\n",
    "        \n",
    "        self.h_ = h_\n",
    "        if self.return_pnl_component: \n",
    "            self.pnl_ = compute_pnl_components(self.h_, self.ret, vol_liquidity_factor=self.vol_liquidity_factor)\n",
    "        else: \n",
    "            self.pnl_ = (\n",
    "                h_.shift(1).mul(self.ret).sum(axis=1)[\n",
    "                    self.start_date: self.end_date]\n",
    "            )\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.backtesting_with_cost import compute_pnl_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnlc = compute_pnl_components(m0.h_, ret, vol_liquidity_factor=vol_liquidity_factor)\n",
    "line(pnlc, cumsum=True, title='Industry momentum: vanilla markowitz (variable risk)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting with cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.backtesting_with_cost import BacktesterWithCost, MeanVarianceWithCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0_ = BacktesterWithCost(MeanVarianceWithCost(), ret, vol_liquidity_factor=None).train(features, target)\n",
    "m0.pnl_.equals(m0_.pnl_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BacktesterWithCost(MeanVarianceWithCost(), ret, vol_liquidity_factor, \n",
    "                       return_pnl_component=True).train(features, target)\n",
    "line(m.pnl_, cumsum=True, title='Industry momentum: markowitz with cost (variable risk)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'net = gross - impact cost'\n",
    "line({'basline': pnlc[c], 'optimised with cost': m.pnl_[c]}, cumsum=True, \n",
    "     title = f'Industry momentum: {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the average holding periods, we see a sharp increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average holding period (in month):\\n - baseline = {average_holding_period(m0.h_):.1f},\\n - optimised with quadratic cost = {average_holding_period(m.h_):.1f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot below shows at the industry level: \n",
    "    \n",
    "- the average liquidity factor\n",
    "- the average holding period \n",
    "\n",
    "Intuitive, the more expensive it is to trade a sector, the longer the holding period should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "avp = pd.Series({c: average_holding_period(m.h_[c]) for c in m0.h_.columns})\\\n",
    "        .div(pd.Series({c: average_holding_period(m0.h_[c]) for c in m0.h_.columns})).sub(1)\n",
    "       \n",
    "df = pd.concat({'vol liquidity factor': vol_liquidity_factor.loc[m0.h_.index[0]:].mean(), \n",
    "                'average holding period per industry: pct change': avp}, axis=1)\n",
    "\n",
    "cols = list(df.columns)\n",
    "idx = list(df.index)\n",
    "\n",
    "ax.scatter(df.iloc[:, 0].values, df.iloc[:, 1].values)\n",
    "ax.set_xlabel(cols[0])\n",
    "ax.set_ylabel(cols[1])\n",
    "xshift, yshift, rotation=.1, 0, 0\n",
    "for i, txt in enumerate(idx):\n",
    "    ax.text(df.iloc[i, 0] + xshift, df.iloc[i, 1]+ yshift, txt, fontsize=12, rotation=rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Hlth ', 'Money']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "for i, c in enumerate(cols): \n",
    "    df = pd.concat({'baseline': m0.h_[c], 'optimised with cost': m.h_[c]}, axis=1)\n",
    "    line(df, title=f'Holdings: {c} (correlation={df.corr().iloc[0, 1]: .2f})', ax=ax[i], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For healthcare, the volality/liquidity factor seems high on average, but decreases sharply over the period -- which explains that the average holding period increases less than expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge backtest with cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from skfin.estimators import Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_ = {'constant risk (baseline)': make_pipeline(StandardScaler(with_mean=False), \n",
    "                                                         Ridge(), \n",
    "                                                         MeanVariance(constant_risk=True)), \n",
    "               'variable risk':make_pipeline(StandardScaler(with_mean=False), \n",
    "                                                         Ridge(), \n",
    "                                                         MeanVariance(constant_risk=False))}\n",
    "line({k: Backtester(v, ret).train(features, target).pnl_ for k, v in estimators_.items()}, \n",
    "     cumsum=True, title='Industry momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_ = make_pipeline(StandardScaler(with_mean=False), \n",
    "                           Ridge(), \n",
    "                           MeanVarianceWithCost())\n",
    "m0_ = BacktesterWithCost(estimator_, ret, vol_liquidity_factor=None).train(features, target)\n",
    "\n",
    "pnlc = compute_pnl_components(m0_.h_, ret, vol_liquidity_factor=vol_liquidity_factor)\n",
    "line(pnlc, cumsum=True, title='Industry cross-effects momentum: vanilla markowitz (variable risk)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ = BacktesterWithCost(estimator_, ret, vol_liquidity_factor=vol_liquidity_factor, \n",
    "                       return_pnl_component=True).train(features, target)\n",
    "line(m_.pnl_, cumsum=True, title='Industry cross-effects momentum: markowitz with cost (variable risk)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between the baseline industry momentum strategy and the strategies that lean cross-effects (e.g. learning with a Ridge estimator) is these strategies are faster. In this case, taking cost into account to slow down the strategy is even more important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average holding period (in month):\\n - baseline Ridge = {average_holding_period(m0_.h_):.1f},\\n - optimised with quadratic cost = {average_holding_period(m_.h_):.1f}.')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
