{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "523ba18a",
   "metadata": {},
   "source": [
    "# Style Analysis and Factor Decomposition: Evaluating Industry Momentum and Berkshire Hathaway's Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab48aa5",
   "metadata": {},
   "source": [
    "In this section, we compare the performance of the Industry momentum derived in previous sections with other factors (e.g. Stock Momentum, Value, Size, etc.). In particular, we discuss the Style regression of Sharpe (1992). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ab995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "from skfin.backtesting import Backtester\n",
    "from skfin.datasets_ import load_kf_returns\n",
    "from skfin.mv_estimators import MeanVariance\n",
    "from skfin.plot import bar, heatmap, line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7a45a",
   "metadata": {},
   "source": [
    "## Style analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e61dc",
   "metadata": {},
   "source": [
    "As introduced by Sharpe (1992), Style Analysis is the process of determining what type of investment behaviour an investor or a money manager employs when making investment decisions.\n",
    "\n",
    "A regression is used to determine the factor exposures $\\langle \\beta_1,... \\beta_K\\rangle$ where:\n",
    "\n",
    "$$ r = \\alpha + \\beta_1 r_1^{\\Phi} + ... + \\beta_K r_K^{\\Phi} + \\epsilon$$\n",
    "\n",
    "Additional constraints might be added to “regularize\" the regression such as non-negative exposures : $\\beta_k \\geq 0$ and/or sum equals 1: $\\sum_{k=1}^{K} \\beta_k = 1$.\n",
    "\n",
    "Frazzini, Kabiller and Pedersen (2013) state that: \n",
    "\n",
    "> Berkshire Hathaway has realized a Sharpe ratio of 0.76, higher than any other stock or mutual fund with a history of more than 30 years, and Berkshire has a significant alpha to traditional risk factors.\"\n",
    "\n",
    "How did Warren Buffet do it? We use a “style analysis\" approach applied to equity factors to address this question.\n",
    "\n",
    "The main regression is:\n",
    "$$r_t = \\alpha +\\beta_1 MKT_t +\\beta_2 SMB_t +\\beta_3 HML_t +\\beta_4 UMD_t + \\beta_5 BAB_t + \\beta QMJ_t +\\epsilon_t$$\n",
    "\n",
    "where the factors are\n",
    "\n",
    "- $r_t$ : excess return of the Berkshire Hathaway stock\n",
    "\n",
    "- $MKT_t$ (market): excess market return\n",
    "\n",
    "-  $SMB_t$ (size): small minus big\n",
    "\n",
    "-  $HML_t$ (value): high book-to-market minus low book-to-market\n",
    "\n",
    "-  $UMD_t$ (momentum): up minus down\n",
    "\n",
    "-  $BAB_t$ (betting-against-beta): safe (low beta) minus risky (high beta)\n",
    "\n",
    "- $QMJ_y$ (quality): quality minus junk\n",
    "\n",
    "Can we replicate this finding? Fortunately Steve Lihn (on GitHub) already did it.\n",
    "\n",
    "Data: github.com/slihn/buffetts_alpha_R/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/l1_frazzini_table4heading.PNG\"))\n",
    "display(Image(\"images/l1_frazzini_table4.PNG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b6d1f7",
   "metadata": {},
   "source": [
    "- The characteristics of the investment of Warren Buffet: high loadings on replicable factors such as beta, size, value and quality – and a negative loading on momentum.\n",
    "\n",
    "\n",
    "- At least in this replication of the paper's results (with slightly different data), the intercept is no longer statistically significant – it might still be economically significant!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.datasets_ import load_buffets_data\n",
    "\n",
    "data = load_buffets_data(cache_dir=\"data\").assign(\n",
    "    excess_return=lambda x: x[\"BRK.A\"] - x[\"RF\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8653901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import api\n",
    "\n",
    "m1 = api.OLS(data[\"excess_return\"], api.add_constant(data[\"MKT\"])).fit()\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21254001",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = []\n",
    "for cols in [\n",
    "    [\"MKT\", \"SMB\", \"HML\", \"UMD\"],\n",
    "    [\"MKT\", \"SMB\", \"HML\", \"UMD\", \"BAB\"],\n",
    "    [\"MKT\", \"SMB\", \"HML\", \"UMD\", \"BAB\", \"QMJ\"],\n",
    "]:\n",
    "    m_ = api.OLS(data[\"excess_return\"], api.add_constant(data[cols])).fit()\n",
    "    summaries += [m_.summary()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_table(tbl):\n",
    "    df = pd.DataFrame(tbl.tables[1].data)\n",
    "    idx = df.iloc[1:, 0]\n",
    "    return pd.DataFrame(\n",
    "        df.iloc[1:, [1, 3]].astype(float).values,\n",
    "        index=idx.rename(None),\n",
    "        columns=[\"coef\", \"tstat\"],\n",
    "    ).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([prettify_table(v) for v in summaries], axis=1).fillna(0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf8bed",
   "metadata": {},
   "source": [
    "The coefficients are qualitatively close to the results in the paper -- with the except of the `BAB` coefficients not being statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12355465",
   "metadata": {},
   "source": [
    "## Industry momentum factor exposure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc5922",
   "metadata": {},
   "source": [
    "In this section, we go back to the Industry momentum backtest and decompose it on the factors as computed by Ken French. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0310386",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_data = load_kf_returns(cache_dir=\"data\")\n",
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:\"1999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c9e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_X = lambda x: x.rolling(12).mean().fillna(0)\n",
    "transform_y = lambda x: x.shift(-1)\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl0 = Backtester(MeanVariance()).train(features, target, ret)\n",
    "line(pnl0, cumsum=True, title=\"Industry momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"F-F_Research_Data_Factors\", \"F-F_Momentum_Factor\"]\n",
    "df = pd.concat([load_kf_returns(c)[\"Monthly\"] for c in files], axis=1)[\"1945\":\"1999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(df.corrwith(pnl0), horizontal=True, title=\"Correlation with industry momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e8a63-8e35-4dcd-88a1-41f01148ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = df.join(pnl0.rename(\"IndustryMom\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df20fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "line(\n",
    "    pd.concat({\"Stock momentum\": df[\"Mom\"], \"Industry momentum\": pnl0}, axis=1).pipe(\n",
    "        lambda x: x.div(x.std())\n",
    "    ),\n",
    "    cumsum=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24989264",
   "metadata": {},
   "source": [
    "The main issue with this statistical decomposition is that the estimation is done \"full sample\". In the next section, we estimate the Momentum loading on rolling windows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145292e",
   "metadata": {},
   "source": [
    "## Residual pnl "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8c34fe6-e336-45a3-ac44-5a0b7336c5e6",
   "metadata": {},
   "source": [
    "The residual pnl is defined as the difference between the pnl of a strategy and the pnl that can be attributed to the strategy’s exposure to a set of benchmarks. In other words, it is the portion of the strategy’s pnl that remains after removing the component explained by its projection onto the chosen benchmarks, reflecting the strategy’s performance that is independent of those benchmarks.\n",
    "\n",
    "To run the rolling estimation decomposition, we use the function `fit_predict` used in previous sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ad772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.backtesting import fit_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"1945-01-01\"\n",
    "max_train_size = 60\n",
    "test_size = 1\n",
    "params = dict(max_train_size=max_train_size, test_size=test_size, gap=0)\n",
    "params[\"n_splits\"] = (len(data_) - max_train_size) // test_size\n",
    "cv_ = TimeSeriesSplit(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7357734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_hat, estimator_ = zip(\n",
    "    *[\n",
    "        fit_predict(\n",
    "            estimator=LinearRegression(),\n",
    "            X=data_.drop([\"IndustryMom\", \"RF\"], axis=1),\n",
    "            y=data_[\"IndustryMom\"],\n",
    "            train=train,\n",
    "            test=test,\n",
    "            return_estimator=True,\n",
    "        )\n",
    "        for train, test in cv_.split(data_[\"IndustryMom\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_hat = pd.Series(\n",
    "    np.concatenate(pnl_hat), index=data_[\"IndustryMom\"].index[max_train_size:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a57d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "line(\n",
    "    {\n",
    "        \"pnl0\": pnl0[max_train_size:],\n",
    "        \"predict\": pnl_hat,\n",
    "        \"residue\": pnl0[max_train_size:] - pnl_hat,\n",
    "    },\n",
    "    cumsum=True,\n",
    "    title=\"Rolling residual decomposition\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edad7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "line(\n",
    "    pd.DataFrame([m.intercept_ for m in estimator_], index=pnl_hat.index),\n",
    "    title=\"Intercept coefficient\",\n",
    "    ax=ax[0],\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "line(\n",
    "    pd.DataFrame(\n",
    "        [m.coef_ for m in estimator_],\n",
    "        columns=data_.drop([\"IndustryMom\", \"RF\"], axis=1).columns,\n",
    "        index=pnl_hat.index,\n",
    "    ),\n",
    "    title=\"Slope coefficients\",\n",
    "    loc=\"best\",\n",
    "    ax=ax[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624bc2f",
   "metadata": {},
   "source": [
    "Over this period, the simple Industry momentum strategy seems to have zero residual relative to other factors. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "skfin 2024",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
