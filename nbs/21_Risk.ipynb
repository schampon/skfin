{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key ingredient of portfolio construction is the ability to predict portfolio risk (in particular, with a risk-model) to be able to properly size the positions. Of course, an important assumption of the markowitz optimisation is the normality of returns. In this section, we evaluate the non-normality of backtest pnls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "from skfin.plot import *\n",
    "from skfin.datasets import load_kf_returns\n",
    "from skfin.mv_estimators import MeanVariance \n",
    "from skfin.backtesting import Backtester\n",
    "from skfin.metrics import sharpe_ratio\n",
    "from skfin.estimators import RidgeCV, MultiOutputRegressor, MLPRegressor\n",
    "\n",
    "returns_data = load_kf_returns(cache_dir='data')\n",
    "ret = returns_data['Monthly']['Average_Value_Weighted_Returns'][:'1999']\n",
    "\n",
    "transform_X = lambda x: x.rolling(12).mean().fillna(0).values\n",
    "transform_y = lambda x: x.shift(-1).values\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk in the industry momentum backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.metrics import sharpe_ratio, drawdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the Industry momentum benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backtester(MeanVariance(), ret).train(features, target)\n",
    "h0, pnl0, estimators0 = m.h_, m.pnl_, m.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "line(pnl0.rename('Industry momentum'), cumsum=True, loc='best', title='Cumulative pnl', ax=ax[0])\n",
    "line(pnl0.rolling(36).std().mul(np.sqrt(12)), title='Annualized risk', legend=False, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line(pnl0.pipe(drawdown), title='Drawdown in unit of annualized risk', legend=False, figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line(pnl0.rename('pnl').to_frame().assign(pnl_abs=lambda x: x.pnl.abs()).sort_values('pnl_abs').reset_index(drop=True)['pnl'], \n",
    "     cumsum=True, title='Cumulative returns sorted by absolute monthly return', legend_sharpe_ratio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return covariance eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk-model is defined here as the covariance of returns $V$. To understand its impact on the backtest, it is important to remember that in the mean-variance optimisation, it is the inverse of the covariance matrix $V^{-1}$ that is used. \n",
    "\n",
    "Viewed from the point of view of a singular value decomposition, the smallest eigenvalues of $V$ are not only estimated with noise, but their impact is magnified in $V^{-1}$, leading to potentially significant noise in the estiamte of positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in m.cv.split(ret): \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, _ = np.linalg.svd(ret.iloc[train].cov())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows that the largest eigenvalue is two-order of magnitude larger than the smallest one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series(D, np.arange(1, 13))\n",
    "scatter(df, xscale='log', yscale='log', xlabel='Eigenvalue (log scale)', ylabel='Rank (log scale)', \n",
    "        xticks=[1, 2, 4, 8, 16], yticks=[ .1, 1, 10, 100], title='Distribution of return covariance eigenvalues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The ratio of the largest to the smallest eigenvalue is {D[0]/D[-1]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk model estimation\n",
    "\n",
    "The insight of Ledoit and Wolf (2004): use a weighted average of two matrices to reduce estimation error\n",
    "\n",
    "- the empirical covariance matrix V is asymptotically an unbiased estimated – but with a slow convergence for sample samples\n",
    "\n",
    "- there are biased estimators but with a faster rate of convergence –- for instance the diagonal D of V -- and on smaller samples, such biased estimators can be more efficient than the unbiased ones\n",
    "\n",
    "- The covariance matrix used in the portfolio optimisation is \n",
    "\n",
    "$$V_{\\omega} = \\omega D + (1-\\omega) V.$$\n",
    "\n",
    "How to determine $\\omega$? Ledoit and Wolf (2004) minimize a norm that applies to\n",
    "matrices (Frobenius norm)\n",
    "\n",
    "For a given portfolio $h$, the risk-bias is given by \n",
    "\n",
    "$$ \\text {RiskBias}  = Std \\left[\\frac{h^T r}{\\sqrt{h^T  \\hat{V}(\\omega) h }} \\right] -1 , $$\n",
    "where the variance is evaluated over empirical returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import LedoitWolf, ShrunkCovariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value of the `shrinkage` parameter for `ShrunkCovariance` is 0.1. When `shrinkage=0`, there is no shrinkage and when `shrinkage=1`, all the off-diagonal terms are set to zero and the covariance matrix is diagonal.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_V_ = lambda x: ShrunkCovariance(shrinkage=0.1).fit(x).covariance_\n",
    "m = Backtester(MeanVariance(transform_V=transform_V_), ret).train(features, target)\n",
    "h, pnl, estimators = m.h_, m.pnl_, m.estimators_\n",
    "line({'benchmark': pnl0, 'shrunk covariance': pnl}, cumsum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation of risk with the shrunk covariance is much closer to the ex-ante risk (of 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line({'benchmark': pnl0.rolling(36).std(), 'shrunk covariance': pnl.rolling(36).std()}, \n",
    "     title='Rolling risk bias (36-month)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio of the largest to the smallest eigenvalue is an order of magnitude smaller for the backtest with the shrunk covariance relative to the benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eigenvalues = lambda estimators: pd.DataFrame([np.linalg.svd(m.V_, compute_uv=False) for m in estimators])\n",
    "ratio_largest_smallest_eigenvalue = lambda x: x.pipe(lambda x: x.iloc[:,0]/x.iloc[:,-1])\n",
    "\n",
    "eigenvalues0 = get_eigenvalues(estimators0)\n",
    "eigenvalues = get_eigenvalues(estimators)\n",
    "\n",
    "line({'benchmark': eigenvalues0.pipe(ratio_largest_smallest_eigenvalue),\n",
    "      'shrunk covariance': eigenvalues.pipe(ratio_largest_smallest_eigenvalue)}, yscale='log', \n",
    "    title='Ratio of the largest-to-the-smallest-eigenvalues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnls = {}\n",
    "for shrinkage in [0, .01, .1,  1]: \n",
    "    transform_V_ = lambda x: ShrunkCovariance(shrinkage=shrinkage).fit(x).covariance_\n",
    "    estimator = MeanVariance(transform_V=transform_V_)\n",
    "    pnls[shrinkage] = Backtester(estimator,ret).train(features, target).pnl_\n",
    "line(pnls, cumsum=True, title='Robustness for different value of the shrinkage parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related shrinkage is to use the `LedoitWolf` method to determine the shrinkage and it yield similar performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_V_ = lambda x: LedoitWolf().fit(x).covariance_\n",
    "estimator = MeanVariance(transform_V=transform_V_)\n",
    "pnl_ = Backtester(estimator,ret).train(features, target).pnl_\n",
    "line({'benchmark': pnl0, 'shrunk covaraince': pnl, 'ledoit-wolf': pnl_}, \n",
    "     cumsum=True, title='Ledoit-Wolf shrinkage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key empirical point is that the sharpe ratio is maximized for a covariance that involves a small amount of shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normality\n",
    "\n",
    "At the stock-level, non-normality (e.g. skewness or kurtosis) may not be a significant problem:\n",
    "- the portfolio might be short a stock with negative skewness\n",
    "\n",
    "-  part of the stock kurtosis might diversify away at the portfolio level.\n",
    "\n",
    "But factor-level non-normality is harder to diversify – especially the returns of strategy based on risk-premia (which are generally non-normally distributed):\n",
    "\n",
    "- by definition, in risk-off environments, these strategies do not pay off and the left tails of the return distribution can be very “thick\" leading to “rare disasters\"\n",
    "\n",
    "In this section, we discuss how to document non-normality:\n",
    "\n",
    "- use some test statistics that involve skewness and kurtosis. \n",
    "\n",
    "- illustrate some methods using industry momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics of higher moments: \n",
    "\n",
    "-  $skewness =  \\frac{E[(x - \\bar{x})^3]}{\\sigma_x^3}$ \n",
    "\n",
    "-  $kurtosis = \\frac{E[(x - \\bar{x})^4]}{\\sigma_x^4}$\n",
    "\n",
    "- Jarque-Bera statistics $JB = \\frac{T}{6} \\left(skewness^2 + \\frac{(kurtosis-3)^2}{4} \\right)$ \n",
    "\n",
    "- If the observations $\\{x_1,..,x_T\\}$ are independant and follow a Normal distribution, then \n",
    "\n",
    "    1. $skewness=0$ \n",
    "\n",
    "    1. $kurtosis=3$ \n",
    "\n",
    "    1. $JB$ follows of Chi-squared distribution with two degrees of freedom. \n",
    "\n",
    "- The third assertion provides a way to test whether a variable is Normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew, jarque_bera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normally distributed random data**:\n",
    "\n",
    "- we can _not_ reject the null hypothesis that the data follows is a Normal distribution! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T, N) = ret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0, 1, T)   # create random values based on a normal distribution\n",
    "\n",
    "print(f'Excess kurtosis of normal distribution (should be 0): {kurtosis(x):.3f}')\n",
    "print(f'Skewness of normal distribution (should be 0): {skew(x):.3f}')\n",
    "print(f'Jarque beta of normal distribution (should be 0): {jarque_bera(x)[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `fisher=False`, the function `kurtosis` computes the raw kurtosis (the default is `fisher=True`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(np.random.normal(0, 1, T), fisher=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniformly distributed random data**: \n",
    "\n",
    "- we can reject at any confidence level the null hypothesis that the data follows a Normal distribution! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 1, T)   # create random values based on a normal distribution\n",
    "\n",
    "print(f'Excess kurtosis of normal distribution (should be 0): {kurtosis(x):.3f}')\n",
    "print(f'Skewness of normal distribution (should be 0): {skew(x):.3f}')\n",
    "print(f'Jarque beta of normal distribution (should be 0): {jarque_bera(x)[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Industry momentum data**: \n",
    "\n",
    "- we can also reject the null hypothesis of a Normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pnl\n",
    "\n",
    "print(f'Excess kurtosis of normal distribution (should be 0): {kurtosis(x):.3f}')\n",
    "print(f'Skewness of normal distribution (should be 0): {skew(x):.3f}')\n",
    "print(f'Jarque beta of normal distribution (should be 0): {jarque_bera(x)[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Pnl std={pnl.std():.2f}')\n",
    "pnl.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The test in the notebook shows that the normality assumption is easily rejected for the momentum strategy return – there are a lot of observations (T large) and significant deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The statistics of rolling sharpe ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now focus on 3-year rolling sharpe ratio:\n",
    "\n",
    "- A 3-year horizon is the natural horizon to evaluate the performance of investment strategies.\n",
    "\n",
    "- Significant underperformance over 3 years is almost always a show-stopper!\n",
    "\n",
    "- In particular, we assess the impact of skewness and kurtosis on the rolling sharpe ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemma** [Lo, 1996]. When the underlying data is iid Normally distributed, the limiting distribution of the estimated  monthly sharpe ratio $\\hat{S}$ (relative to the true unobserved $S$) is \n",
    "$$\n",
    "\\sqrt{T} (\\hat{S} - S) \\rightarrow N\\left(0, 1 + \\frac{IR^2}{2}\\right) \n",
    "$$\n",
    "*Proof*. For independently Normally distributed returns, we have\n",
    "$$\n",
    "\\sqrt{T} \\left[ \\begin {array}{c} \\hat{\\mu} - \\mu \\\\ \\hat{\\sigma}^2- \\sigma^2  \\end {array} \\right] \\rightarrow N \\left( \\left[ \\begin {array}{c} 0 \\\\ 0 \\end {array} \\right];  \\left[ \\begin {array}{cc} \\sigma^2 & 0 \\\\ 0 & 2 \\sigma^4  \\end {array} \\right]  \\right)\n",
    "$$\n",
    "For $S = g(\\mu,\\sigma^2) = \\frac{\\mu}{\\sqrt{\\sigma^2}}$, the asymptotic variance of $\\hat{S}$ is \n",
    "$$\n",
    " \\left[ \\begin {array}{c} \\frac{\\partial g}{\\partial \\mu} \\\\ \\frac{\\partial g}{\\partial (\\sigma^2)} \\end {array} \\right]^T \\left[ \\begin {array}{cc} \\sigma^2 &  0 \\\\ 0 & 2 \\sigma^4  \\end {array} \\right]  \\left[ \\begin {array}{c} \\frac{\\partial g}{\\partial \\mu} \\\\ \\frac{\\partial g}{\\partial (\\sigma^2)} \\end {array} \\right]  = \\frac{1}{\\sigma^2} \\sigma^2 +   \\left(- \\frac{\\mu}{2\\sigma^3}\\right)^2 (2 \\sigma^4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corollary.** The minimum monthly $S_0$ for a monthly strategy where the Sharpe ratio is always statistically different from 0 at the 5\\%-confidence level over a window of $T$ months is given by \n",
    "\n",
    "$$S_0 - 1.96 \\sqrt{\\frac{1+\\frac{S_0^2}{2}}{T}} =0  \\Leftrightarrow  S_0 = \\sqrt{\\frac{1}{\\frac{T}{1.96^2}-1/2}} $$\n",
    "\n",
    "- Rule of thumb: for a 36-month horizon, then the monthly $S_0 \\approx 0.35$ or after annualization \n",
    "\n",
    "$$ S_0^{\\text {annualized}} \\approx .35 \\times  \\sqrt{12} = 1.16 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the returns are not Normally distributed ($skewness \\neq 0$ and (excess) $kurtosis\\neq 0$), the Central Limit theorem still ensures the asymptotic normality. (In what follows, `kurtosis` refers to the \"excess kurtosis.)\n",
    "\n",
    "\n",
    "**Lemma** [Mertens, 2002] The asymptotic distribution of $\\hat{S}$ is  \n",
    "\n",
    "$$\n",
    "\\sqrt{T} (\\hat{S} - S) \\rightarrow N\\left(0, V_{\\infty} \\right) \n",
    "$$\n",
    "where $V_{\\infty} = 1 + \\frac{S^2}{2} - skewness \\times S + \\frac{kurtosis \\times S^2}{4}$.\n",
    "\n",
    "*Proof.* The asymptotic variance of $\\left[\\begin {array}{c} \\hat{\\mu} - \\mu \\\\ \\hat{\\sigma}^2 - \\sigma^2 \\end {array} \\right]$ is: \n",
    "$$\n",
    "E\\left[\\begin {array}{cc} (r_t - \\mu)^2 & (r_t - \\mu)[(r_t - \\mu)^2 - \\sigma^2]\\\\ (r_t - \\mu)[(r_t - \\mu)^2 - \\sigma^2] & [(r_t - \\mu)^2 - \\sigma^2]^2 \\end {array} \\right]\\\\\n",
    "= \\left[ \\begin {array}{cc} \\sigma^2 & E[(r_t - \\mu)^3] \\\\ E[(r_t - \\mu)^3] & 2 E[(r_t - \\mu)^4] - \\sigma^4  \\end {array} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corollary.** The minimum $S_0(skewness, kurtosis)$ for a monthly strategy where the information is always statistically different from 0 at the 5%-confidence level over a window of $T$ months is increasing in *kurtosis* and decreasing in *skewness*. \n",
    "\n",
    "*Proof.* The function $f(S,skewness,kurtosis)$ \n",
    "$$\n",
    "= S - 1.96 \\sqrt{\\frac{ 1 + \\frac{S^2}{2} - skewness \\times S + \\frac{kurtosis \\times S^2}{4}}{T}  }\n",
    "$$\n",
    "is increasing in $S$ and *skewness* and decreasing in *kurtosis*, so that $S_0$ defined by $f(S_0,skewness,kurtosis)=0$ is decreasing in *skewness* and increasing in *kurtosis*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr3y = pnl.rolling(36).apply(sharpe_ratio)\n",
    "line(sr3y, legend=False, title='3-year rolling sharpe ratio', start_date='1945')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the two lower bounds for the sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr3y_lb = sr3y - 1.96 * np.sqrt((1 + .5 * sr3y**2) / 36) * np.sqrt(12)\n",
    "skew3y = pnl.rolling(36).apply(skew)\n",
    "kurtosis3y = pnl.rolling(36).apply(kurtosis)\n",
    "sr3y_lb_bis = sr3y - 1.96 * np.sqrt((1+.5 * sr3y**2 - skew3y *sr3y + .25*kurtosis3y *sr3y**2)/36) * np.sqrt(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line({'sr': sr3y, 'sr minus 1.96 std': sr3y_lb, 'sr minus 1.96 adjStd': sr3y_lb_bis}, start_date='1945')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even generic momentum strategies (including industry momentum) have a fairly strong Sharpe ratio... \n",
    "\n",
    "-  ... but the performance includes kurtosis/skewness risk premia, with occasional deep underperformance over a 3-year horizon. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
