{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-variance estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markowitz portfolio optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we review the derivation of mean-variance optimisation for a universe with $N$ assets: $r$ is a vector of size $N$; $\\alpha$ is the return forecast: $\\alpha = E(r)$.\n",
    "\n",
    "Note: for a vector $v$, we denote $v^T$ as the transpose of $v$. \n",
    "\n",
    "\n",
    "**Lemma** [mean-variance]: the allocation that maximizes the utility $h^T \\alpha - \\frac{h^T V h}{2 \\lambda}$ is\n",
    "$$h = \\lambda V^{-1} \\alpha, $$ \n",
    "where $\\lambda$ is the risk-tolerance.\n",
    "\n",
    "The ex-ante risk is $h^T V h = \\lambda^2 \\alpha^T V^{-1} \\alpha$ and the ex-ante Sharpe ratio is\n",
    "$$\n",
    "S = \\frac{h^T E(r)}{\\sqrt{h^T V h}} = \\sqrt{\\alpha^T V^{-1} \\alpha}. \n",
    "$$\n",
    "\n",
    "**Corollary**: The maximisation of the sharpe ratio is equivalent (up to a scaling factor) the mean-variance optimisation. \n",
    "\n",
    "The mean-variance formula is extended to account for the linear constraints\n",
    "$$A h = b. $$ \n",
    "\n",
    "To do so, we introduce the Lagrangian $\\mathcal {L}$ (and Lagrange multiplier $\\xi$)\n",
    "\n",
    "$$\n",
    "\\mathcal {L}= h^T \\alpha - \\frac{h^T V h}{2\\lambda} - (h^T A^T - b^T)\\xi\n",
    "$$\n",
    "\n",
    "The Lagrange multiplier $\\xi$ is a `tuning parameter` chosen exactly so that the constraint above holds. At the optimal value of $\\xi$, the constrained problem boils down to an unconstrained problem with the adjusted return forecast $\\alpha - A^T \\xi$.\n",
    "\n",
    "\n",
    "**Lemma**: the allocation that maximizes the utility $h^T \\alpha - \\frac{h^T V h}{2 \\lambda}$ under the linear constraint $A h = b$ is\n",
    "\n",
    "$$ h = V^{-1} A^T \\left(A V^{-1} A^T \\right)^{-1} b + \\lambda V^{-1} \\left[\\alpha - A^T \\left(A V^{-1} A^T \\right)^{-1} A V^{-1} \\alpha \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Proof*: the first-order condition is\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal {L}}{\\partial h} = \\alpha - \\frac{V h}{\\lambda} - A^T \\xi =0  \\Leftrightarrow  h = \\lambda V^{-1}[\\alpha - A^T \\xi] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter $\\xi$ is chosen so that $A h = b$\n",
    "\n",
    "$$b = Ah = \\lambda A  V^{-1}[\\alpha - A^T \\xi]  \\Rightarrow  \\xi = [A V^{-1}A^T]^{-1} \\left[ A  V^{-1}\\alpha - \\frac{b}{\\lambda}  \\right]\n",
    "$$\n",
    "\n",
    "The holding vector under constraint is\n",
    "\n",
    "$$ h_{\\lambda} = \\underbrace {V^{-1} A^T \\left(A V^{-1} A^T \\right)^{-1} b}_{\\text {minimum variance portfolio}} + \\underbrace { \\lambda V^{-1} \\left[\\alpha - A^T \\left(A V^{-1} A^T \\right)^{-1} A V^{-1} \\alpha \\right]}_{\\text {speculative portfolio}} $$\n",
    "\n",
    "- The first term is what minimises the risk $h^T V h$ under the constraint $Ah =b$ (in particular, it does not depend on expected returns or risk-tolerance).\n",
    "\n",
    "- The second term is the speculative portfolio (it is sensitive to both inputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The efficient frontier is the relation between  expected portfolio return $h^T \\alpha$ and portfolio standard deviation $\\sqrt{h^T V h}$ for varying level of risk-tolerance\n",
    "$$ (x, y) \\mapsto \\left(h_{\\lambda}^T \\alpha, \\sqrt{h_{\\lambda}^T V h_{\\lambda}} \\right)$$\n",
    "\n",
    "When $b=0$, the efficient frontier between $h_{\\lambda}^T \\alpha$ and $\\sqrt{h_{\\lambda}^T V h_{\\lambda}}$ is a line through $(0,0)$; otherwise, it is a parabolic curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on pure \"alpha views\" -- that is, long-short \"cash-neutral\" portfolios where the sum of holdings is zero. In this case $b=0$ and $A = \\textbf{1}$ where\n",
    "\n",
    "$$ \\textbf {1} = \\left[\\begin {array}{ccc} 1  & \\ldots & 1  \\end {array} \\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Mean-variance estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next set of helper file, we introduce two main functions: \n",
    "\n",
    "- a function that computes mean-variance holdings for batches\n",
    "\n",
    "- a `MeanVariance` class that follows the `sklearn` api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%%writefile ../skfin/mv_estimators.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from skfin.metrics import sharpe_ratio\n",
    "\n",
    "\n",
    "def compute_batch_holdings(pred, V, A=None, past_h=None, constant_risk=False):\n",
    "    \"\"\"\n",
    "    compute markowitz holdings with return prediction \"mu\" and covariance matrix \"V\"\n",
    "\n",
    "    mu: numpy array (shape N * K)\n",
    "    V: numpy array (N * N)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    N, _ = V.shape\n",
    "    if isinstance(pred, pd.Series) | isinstance(pred, pd.DataFrame):\n",
    "        pred = pred.values\n",
    "    if pred.shape == (N,):\n",
    "        pred = pred[:, None]\n",
    "    elif pred.shape[1] == N:\n",
    "        pred = pred.T\n",
    "\n",
    "    invV = np.linalg.inv(V)\n",
    "    if A is None:\n",
    "        M = invV\n",
    "    else:\n",
    "        U = invV.dot(A)\n",
    "        if A.ndim == 1:\n",
    "            M = invV - np.outer(U, U.T) / U.dot(A)\n",
    "        else:\n",
    "            M = invV - U.dot(np.linalg.inv(U.T.dot(A)).dot(U.T))\n",
    "    h = M.dot(pred)\n",
    "    if constant_risk:\n",
    "        h = h / np.sqrt(np.diag(h.T.dot(V.dot(h))))\n",
    "    return h.T\n",
    "\n",
    "\n",
    "class MeanVariance(BaseEstimator):\n",
    "    def __init__(self, transform_V=None, A=None, constant_risk=True):\n",
    "        if transform_V is None:\n",
    "            self.transform_V = lambda x: np.cov(x.T)\n",
    "        else:\n",
    "            self.transform_V = transform_V\n",
    "        self.A = A\n",
    "        self.constant_risk = constant_risk\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.V_ = self.transform_V(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.A is None:\n",
    "            T, N = X.shape\n",
    "            A = np.ones(N)\n",
    "        else:\n",
    "            A = self.A\n",
    "        h = compute_batch_holdings(X, self.V_, A, constant_risk=self.constant_risk)\n",
    "        return h\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sharpe_ratio(np.sum(X * y, axis=1))\n",
    "\n",
    "\n",
    "class Mbj(TransformerMixin):\n",
    "    def __init__(self, positive=False):\n",
    "        self.positive = positive\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        m = LinearRegression(fit_intercept=False, positive=self.positive)\n",
    "        m.fit(X, y=np.ones(len(X)))\n",
    "        self.coef_ = m.coef_ / np.sqrt(np.sum(m.coef_**2))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.dot(self.coef_)\n",
    "\n",
    "\n",
    "class TimingMeanVariance(BaseEstimator):\n",
    "    def __init__(self, transform_V=None, a_min=None, a_max=None):\n",
    "        if transform_V is None:\n",
    "            self.transform_V = lambda x: np.var(x)\n",
    "        else:\n",
    "            self.transform_V = transform_V\n",
    "        self.a_min = a_min\n",
    "        self.a_max = a_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.V_ = self.transform_V(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if (self.a_min is None) & (self.a_max is None):\n",
    "            h = X / self.V_\n",
    "        else:\n",
    "            h = np.clip(\n",
    "                X / np.sqrt(self.V_), a_min=self.a_min, a_max=self.a_max\n",
    "            ) / np.sqrt(self.V_)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.mv_estimators import compute_batch_holdings, MeanVariance\n",
    "from skfin.datasets import load_kf_returns\n",
    "returns_data = load_kf_returns(cache_dir=\"data\", force_reload=True)\n",
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:'1999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, N = ret.shape\n",
    "A = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = compute_batch_holdings(ret.mean(), ret.cov(), A, past_h=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(h.dot(A), [0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.stack([np.ones(N), np.zeros(N)], axis=1)\n",
    "A[0, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = compute_batch_holdings(pred=ret.mean(), V=ret.cov(), A=A, past_h=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A shortcut to compute markowitz weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "display(Image('images/mbj.png',width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trick to compute markowitz weights just with the pnl of different assets \n",
    "\n",
    "- X: pnl of $K$ assets over $T$ days -- so that the shape of X is $[T \\times K]$. \n",
    "\n",
    "- y: vector of ones of size $T$. \n",
    "\n",
    "**Lemma** [Mark Britten-Jones]: the markowitz weights of are proportional to the slope coefficient of a regression of the vector of ones $y$ on the pnls $X$ *with no intercept*. \n",
    "\n",
    "Proof: the coefficient of the regression with no intercept is given by \n",
    "\n",
    "$$ b = (X^T X)^{-1} X^T y  $$\n",
    "\n",
    "The mean of the pnls is given by $\\mu = \\frac{1}{T} X^T y$. The variance of the pnls is $V = \\frac{1}{T} X^T X - \\mu \\mu^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Woodbury identity (https://en.wikipedia.org/wiki/Woodbury_matrix_identity), we have: \n",
    "\n",
    "$$ b = (V + \\mu \\mu^{T})^{-1} \\mu = \\left[ V^{-1} -  \\frac{V^{-1} \\mu \\mu^{T}V^{-1}}{1 + \\mu^T V^{-1} \\mu}  \\right] \\mu = \\frac{V^{-1} \\mu}{1 + \\mu^T V^{-1} \\mu} $$\n",
    "\n",
    "The main trick is to recognise that \n",
    "\n",
    "$$(X^T X)^{-1} X^T y \\propto [X^T X - (X^T y)^T  X^T y ]^{-1} X^T y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-variance from a trade perspective "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rewrite the mean-variance objective as a function of trades $t$ insead of holdings $h$\n",
    "\n",
    "$$ t = h - h_0, $$ \n",
    "\n",
    "where $h_0$ are the previous-period holdings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemma**. If $A h_0 = b$, then  \n",
    "\n",
    "$$\n",
    "\\mathcal {L}= t^T \\left[\\alpha - \\frac{V h_0}{\\lambda}\\right] - \\frac{t^T V t}{2\\lambda} - t^T A^T \\xi\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
