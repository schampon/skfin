{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf768c8",
   "metadata": {},
   "source": [
    "# Mean-variance estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838147a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:32.628855Z",
     "iopub.status.busy": "2023-12-07T08:14:32.628334Z",
     "iopub.status.idle": "2023-12-07T08:14:34.183818Z",
     "shell.execute_reply": "2023-12-07T08:14:34.183095Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd7ab2-f93e-4a41-a9ca-7875c2bca3fe",
   "metadata": {},
   "source": [
    "A portfolio is the ownership of a set of securities that give rights to a stream of payments. The goal of Markowitz portfolio optimisation is to determine the portfolio holdings that maximise the expected return of the portfolio under a risk constraint. Mathematically, it boils down to maximising a \"mean-variance objective\". In this section, we review the mathematics of Markowitz portfolio optimisation and how to implement in `python` \"mean-variance optimisers\" that follow the scikit-learn \"fit/predict\" api. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81ec85",
   "metadata": {},
   "source": [
    "## Markowitz portfolio optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1be97f",
   "metadata": {},
   "source": [
    "The portfolio universe is made of $N$ assets: \n",
    "\n",
    "- $r$ is a vector of returns for each asset (with size $N$); \n",
    "\n",
    "- $\\alpha$ is the asset return forecast: $\\alpha = E(r)$; \n",
    "\n",
    "- $V$ is the return covariance matrix that measures that correlation between each asset: $V = Var(r)$; \n",
    "\n",
    "- $h$ is a vector of positions/holdings in each of these assets. \n",
    "\n",
    "Note: for a vector $v$, we denote $v^T$ as the transpose of $v$. \n",
    "\n",
    "A mean-variance objective is an objective that trades off the portfolio expected return (as $h^T \\alpha$) against the portfolio expected risk (as $h^T V h$). In practice, it is written as: \n",
    "\n",
    "$$U = h^T \\alpha - \\frac{h^T V h}{2 \\lambda},$$\n",
    "\n",
    "where $\\lambda$ is the risk-tolerance.\n",
    "\n",
    "\n",
    "**Lemma** [mean-variance]: the allocation $h$ that maximizes the mean-variance objective is\n",
    "$$h = \\lambda V^{-1} \\alpha. $$\n",
    "\n",
    "The ex-ante risk is $h^T V h = \\lambda^2 \\alpha^T V^{-1} \\alpha$ and the ex-ante Sharpe ratio is\n",
    "$$\n",
    "S = \\frac{h^T E(r)}{\\sqrt{h^T V h}} = \\sqrt{\\alpha^T V^{-1} \\alpha}. \n",
    "$$\n",
    "\n",
    "**Corollary**: The maximisation of the sharpe ratio is equivalent (up to a scaling factor) the mean-variance optimisation. \n",
    "\n",
    "The mean-variance formula is extended to account for the linear constraints\n",
    "$$A h = b. $$ \n",
    "\n",
    "To do so, we introduce the Lagrangian $\\mathcal {L}$ (and Lagrange multiplier $\\xi$)\n",
    "\n",
    "$$\n",
    "\\mathcal {L}= h^T \\alpha - \\frac{h^T V h}{2\\lambda} - (h^T A^T - b^T)\\xi\n",
    "$$\n",
    "\n",
    "The Lagrange multiplier $\\xi$ is a `tuning parameter` chosen exactly so that the constraint above holds. At the optimal value of $\\xi$, the constrained problem boils down to an unconstrained problem with the adjusted return forecast $\\alpha - A^T \\xi$.\n",
    "\n",
    "\n",
    "**Lemma**: the allocation that maximizes the objective $h^T \\alpha - \\frac{h^T V h}{2 \\lambda}$ under the linear constraint $A h = b$ is\n",
    "\n",
    "$$ h = V^{-1} A^T \\left(A V^{-1} A^T \\right)^{-1} b + \\lambda V^{-1} \\left[\\alpha - A^T \\left(A V^{-1} A^T \\right)^{-1} A V^{-1} \\alpha \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0d536",
   "metadata": {},
   "source": [
    "*Proof*: the first-order condition is\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal {L}}{\\partial h} = \\alpha - \\frac{V h}{\\lambda} - A^T \\xi =0  \\Leftrightarrow  h = \\lambda V^{-1}[\\alpha - A^T \\xi] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c02a1",
   "metadata": {},
   "source": [
    "The parameter $\\xi$ is chosen so that $A h = b$\n",
    "\n",
    "$$b = Ah = \\lambda A  V^{-1}[\\alpha - A^T \\xi]  \\Rightarrow  \\xi = [A V^{-1}A^T]^{-1} \\left[ A  V^{-1}\\alpha - \\frac{b}{\\lambda}  \\right]\n",
    "$$\n",
    "\n",
    "The holding vector under constraint is\n",
    "\n",
    "$$ h_{\\lambda} = \\underbrace {V^{-1} A^T \\left(A V^{-1} A^T \\right)^{-1} b}_{\\text {minimum variance portfolio}} + \\underbrace { \\lambda V^{-1} \\left[\\alpha - A^T \\left(A V^{-1} A^T \\right)^{-1} A V^{-1} \\alpha \\right]}_{\\text {speculative portfolio}} $$\n",
    "\n",
    "- The first term is what minimises the risk $h^T V h$ under the constraint $Ah =b$ (in particular, it does not depend on expected returns or risk-tolerance).\n",
    "\n",
    "- The second term is the speculative portfolio (it is sensitive to both inputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f1171",
   "metadata": {},
   "source": [
    "The efficient frontier is the relation between  expected portfolio return $h^T \\alpha$ and portfolio standard deviation $\\sqrt{h^T V h}$ for varying level of risk-tolerance\n",
    "$$ (x, y) \\mapsto \\left(h_{\\lambda}^T \\alpha, \\sqrt{h_{\\lambda}^T V h_{\\lambda}} \\right)$$\n",
    "\n",
    "When $b=0$, the efficient frontier between $h_{\\lambda}^T \\alpha$ and $\\sqrt{h_{\\lambda}^T V h_{\\lambda}}$ is a line through $(0,0)$; otherwise, it is a parabolic curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a583f",
   "metadata": {},
   "source": [
    "We focus on pure \"alpha views\" -- that is, long-short \"cash-neutral\" portfolios where the sum of holdings is zero. In this case $b=0$ and $A = \\textbf{1}$ where\n",
    "\n",
    "$$ \\textbf {1} = \\left[\\begin {array}{ccc} 1  & \\ldots & 1  \\end {array} \\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af92ea-0d4e-44b6-b7d4-4d855d6d1d69",
   "metadata": {},
   "source": [
    "## A shortcut to compute unconstrained mean-variance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1966f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:34.188082Z",
     "iopub.status.busy": "2023-12-07T08:14:34.187821Z",
     "iopub.status.idle": "2023-12-07T08:14:34.211447Z",
     "shell.execute_reply": "2023-12-07T08:14:34.210799Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "display(Image(\"images/mbj.png\", width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093766b-520b-467f-ac9e-8c1b67cf9429",
   "metadata": {},
   "source": [
    "Trick to compute unconstrained mean-variance weights just with the pnl of different assets \n",
    "\n",
    "- X: pnl of $K$ assets over $T$ days -- so that the shape of X is $[T \\times K]$. \n",
    "\n",
    "- y: vector of ones of size $T$. \n",
    "\n",
    "**Lemma** [Mark Britten-Jones]: the markowitz weights of are proportional to the slope coefficient of a regression of the vector of ones $y$ on the pnls $X$ *with no intercept*. \n",
    "\n",
    "Proof: the coefficient of the regression with no intercept is given by \n",
    "\n",
    "$$ b = (X^T X)^{-1} X^T y.  $$\n",
    "\n",
    "The mean of the pnls is given by $\\mu = \\frac{1}{T} X^T y$. The variance of the pnls is $V = \\frac{1}{T} X^T X - \\mu \\mu^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48007e93-7ec5-40f5-ac27-6ade1e45952b",
   "metadata": {},
   "source": [
    "Using the Woodbury identity (https://en.wikipedia.org/wiki/Woodbury_matrix_identity), we have: \n",
    "\n",
    "$$ b = (V + \\mu \\mu^{T})^{-1} \\mu = \\left[ V^{-1} -  \\frac{V^{-1} \\mu \\mu^{T}V^{-1}}{1 + \\mu^T V^{-1} \\mu}  \\right] \\mu = \\frac{V^{-1} \\mu}{1 + \\mu^T V^{-1} \\mu}. $$\n",
    "\n",
    "This implies that the OLS slope coefficient $b$ is proportial to the mean-variance holdings $V^{-1}\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf21a94",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##Â Mean-variance estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bf764",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the following python file, we introduce several functions: \n",
    "\n",
    "- a function that computes mean-variance holdings for batches\n",
    "\n",
    "- a `MeanVariance` class that follows the `sklearn` api\n",
    "\n",
    "- a `Mbj` class that computes unconstrained mean-variance weights with the Britten-Jones (1999) trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7c030",
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:34.215308Z",
     "iopub.status.busy": "2023-12-07T08:14:34.214882Z",
     "iopub.status.idle": "2023-12-07T08:14:34.237459Z",
     "shell.execute_reply": "2023-12-07T08:14:34.236786Z"
    },
    "hidden": true,
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../skfin/mv_estimators.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skfin.metrics import sharpe_ratio\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def compute_batch_holdings(pred, V, A=None, past_h=None, constant_risk=False):\n",
    "    \"\"\"\n",
    "    compute markowitz holdings with return prediction \"mu\" and covariance matrix \"V\"\n",
    "\n",
    "    mu: numpy array (shape N * K)\n",
    "    V: numpy array (N * N)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    N, _ = V.shape\n",
    "    if isinstance(pred, pd.Series) | isinstance(pred, pd.DataFrame):\n",
    "        pred = pred.values\n",
    "    if pred.shape == (N,):\n",
    "        pred = pred[:, None]\n",
    "    elif pred.shape[1] == N:\n",
    "        pred = pred.T\n",
    "\n",
    "    invV = np.linalg.inv(V)\n",
    "    if A is None:\n",
    "        M = invV\n",
    "    else:\n",
    "        U = invV.dot(A)\n",
    "        if A.ndim == 1:\n",
    "            M = invV - np.outer(U, U.T) / U.dot(A)\n",
    "        else:\n",
    "            M = invV - U.dot(np.linalg.inv(U.T.dot(A)).dot(U.T))\n",
    "    h = M.dot(pred)\n",
    "    if constant_risk:\n",
    "        h = h / np.sqrt(np.diag(h.T.dot(V.dot(h))))\n",
    "    return h.T\n",
    "\n",
    "\n",
    "class MeanVariance(BaseEstimator):\n",
    "    def __init__(self, transform_V=None, A=1, constant_risk=True):\n",
    "        if transform_V is None:\n",
    "            self.transform_V = lambda x: np.cov(x.T)\n",
    "        else:\n",
    "            self.transform_V = transform_V\n",
    "        self.A = A\n",
    "        self.constant_risk = constant_risk\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.V_ = self.transform_V(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.A==1:\n",
    "            T, N = X.shape\n",
    "            A = np.ones(N)\n",
    "        else:\n",
    "            A = self.A\n",
    "        h = compute_batch_holdings(X, self.V_, A, constant_risk=self.constant_risk)\n",
    "        return h\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sharpe_ratio(np.sum(X * y, axis=1))\n",
    "\n",
    "\n",
    "class Mbj(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Computing unconstrained mean-variance weights with the Britten-Jones (1999) trick.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, positive=False):\n",
    "        self.positive = positive\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        m = LinearRegression(fit_intercept=False, positive=self.positive)\n",
    "        m.fit(X, y=np.ones(len(X)))\n",
    "        self.coef_ = m.coef_ / np.sqrt(np.sum(m.coef_**2))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.dot(self.coef_)\n",
    "\n",
    "\n",
    "class TimingMeanVariance(BaseEstimator):\n",
    "    def __init__(self, transform_V=None, a_min=None, a_max=None):\n",
    "        if transform_V is None:\n",
    "            self.transform_V = lambda x: np.var(x)\n",
    "        else:\n",
    "            self.transform_V = transform_V\n",
    "        self.a_min = a_min\n",
    "        self.a_max = a_max\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.V_ = self.transform_V(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if (self.a_min is None) & (self.a_max is None):\n",
    "            h = X / self.V_\n",
    "        else:\n",
    "            h = np.clip(\n",
    "                X / np.sqrt(self.V_), a_min=self.a_min, a_max=self.a_max\n",
    "            ) / np.sqrt(self.V_)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3580c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:34.240369Z",
     "iopub.status.busy": "2023-12-07T08:14:34.239916Z",
     "iopub.status.idle": "2023-12-07T08:14:41.844946Z",
     "shell.execute_reply": "2023-12-07T08:14:41.844180Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skfin.datasets import load_kf_returns\n",
    "from skfin.mv_estimators import MeanVariance, compute_batch_holdings\n",
    "\n",
    "returns_data = load_kf_returns(cache_dir=\"data\", force_reload=True)\n",
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:\"1999\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a78e3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:41.847964Z",
     "iopub.status.busy": "2023-12-07T08:14:41.847691Z",
     "iopub.status.idle": "2023-12-07T08:14:41.881315Z",
     "shell.execute_reply": "2023-12-07T08:14:41.880485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "T, N = ret.shape\n",
    "A = np.ones(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9d160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:41.884177Z",
     "iopub.status.busy": "2023-12-07T08:14:41.883897Z",
     "iopub.status.idle": "2023-12-07T08:14:41.914875Z",
     "shell.execute_reply": "2023-12-07T08:14:41.914207Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h = compute_batch_holdings(ret.mean(), ret.cov(), A, past_h=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a6af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:41.917865Z",
     "iopub.status.busy": "2023-12-07T08:14:41.917610Z",
     "iopub.status.idle": "2023-12-07T08:14:41.948044Z",
     "shell.execute_reply": "2023-12-07T08:14:41.947401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(h.dot(A), [0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd9389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:41.950825Z",
     "iopub.status.busy": "2023-12-07T08:14:41.950567Z",
     "iopub.status.idle": "2023-12-07T08:14:41.977693Z",
     "shell.execute_reply": "2023-12-07T08:14:41.977040Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A = np.stack([np.ones(N), np.zeros(N)], axis=1)\n",
    "A[0, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcc200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:41.980551Z",
     "iopub.status.busy": "2023-12-07T08:14:41.980258Z",
     "iopub.status.idle": "2023-12-07T08:14:42.008645Z",
     "shell.execute_reply": "2023-12-07T08:14:42.007974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "h = compute_batch_holdings(pred=ret.mean(), V=ret.cov(), A=A, past_h=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e9ca6",
   "metadata": {},
   "source": [
    "## Pnl metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefe18c",
   "metadata": {},
   "source": [
    "The performance  of a strategy is evaluated through the profit-and-loss (pnl). The time convention is:\n",
    "    \n",
    "- holdings $h_t$ and returns $r_t$ are known for period $t$ -- ie. at the end of period $t$.\n",
    "\n",
    "- so to compute pnl with forward-looking information, the holdings must only depend on information up to $t-1$\n",
    "\n",
    "- in practice, we will have\n",
    "\n",
    "$$ pnl_t = h_{t-1} \\times r_t. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b5bc4",
   "metadata": {},
   "source": [
    "First, the measure that captures the gain of a strategy $E[pnn_t]$ for a level of risk $Var[pnl_t]$ is given by the Sharpe ratio: \n",
    "    \n",
    "$$sr = \\sqrt{N_{\\text{periods per year}}} \\times \\frac{E[pnl_t]}{\\sqrt{Var[pnl_t]}}, $$\n",
    "\n",
    "where $N_{\\text{periods per year}}$ is an annualization factor that accounts for the number of observation per year (e.g. 12 for a monthly strategy, 260 for a strategy with pnls only on business days). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fabad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-07T08:14:42.012047Z",
     "iopub.status.busy": "2023-12-07T08:14:42.011653Z",
     "iopub.status.idle": "2023-12-07T08:14:42.043453Z",
     "shell.execute_reply": "2023-12-07T08:14:42.042783Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../skfin/metrics.py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def test_monthly(df):\n",
    "    return int(len(df) / len(df.asfreq(\"M\"))) == 1\n",
    "\n",
    "\n",
    "def test_bday(df):\n",
    "    return int(len(df) / len(df.asfreq(\"B\"))) == 1\n",
    "\n",
    "\n",
    "def test_day(df):\n",
    "    return int(len(df) / len(df.asfreq(\"D\"))) == 1\n",
    "\n",
    "\n",
    "def sharpe_ratio(df, num_period_per_year=None):\n",
    "    num_period_per_year = None\n",
    "    if test_monthly(df):\n",
    "        num_period_per_year = 12\n",
    "    if test_bday(df):\n",
    "        num_period_per_year = 260\n",
    "    if test_day(df):\n",
    "        num_period_per_year = 365\n",
    "    if num_period_per_year is None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return df.mean() / df.std() * np.sqrt(num_period_per_year)\n",
    "\n",
    "\n",
    "def drawdown(x, return_in_risk_unit=True, window=36, num_period_per_year=12):\n",
    "    dd = x.cumsum().sub(x.cumsum().cummax())\n",
    "    if return_in_risk_unit:\n",
    "        return dd.div(x.rolling(window).std().mul(np.sqrt(num_period_per_year)))\n",
    "    else:\n",
    "        return dd"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
