{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f54912",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421ca52",
   "metadata": {},
   "source": [
    "In this section, we cover the topic of `overfitting`. A folk theorem in asset management is that people are so afraid of overfitting that they tend to (massively) underfit. Or at least, that was the case. Today, better fitting models to extract as much information from a dataset has become a crucial skill. \n",
    "\n",
    "More precisely, `overfitting` a particular dataset provides a baseline for how well a system can learn (e.g. see the Recipe for Training Neural Nets by Andrej Karpathy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd84ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:55:18.942458Z",
     "iopub.status.busy": "2024-11-07T16:55:18.942067Z",
     "iopub.status.idle": "2024-11-07T16:55:20.772696Z",
     "shell.execute_reply": "2024-11-07T16:55:20.771977Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "from skfin.backtesting import Backtester\n",
    "from skfin.datasets import load_kf_returns\n",
    "from skfin.estimators import MLPRegressor, MultiLGBMRegressor, RidgeCV\n",
    "from skfin.metrics import sharpe_ratio\n",
    "from skfin.mv_estimators import MeanVariance\n",
    "from skfin.plot import bar, line\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "returns_data = load_kf_returns(cache_dir=\"data\")\n",
    "ret = returns_data[\"Monthly\"][\"Average_Value_Weighted_Returns\"][:\"1999\"]\n",
    "\n",
    "transform_X = lambda x: x.rolling(12).mean().fillna(0)\n",
    "transform_y = lambda x: x.shift(-1)\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret)\n",
    "\n",
    "from skfin.datasets import load_kf_returns\n",
    "\n",
    "returns_data = load_kf_returns(cache_dir=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05bd3eb",
   "metadata": {},
   "source": [
    "## Ridge CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c777266",
   "metadata": {},
   "source": [
    "A first strategy is to use estimators that embed some form of cross-validation like `RidgeCV`. K-fold cross validation is described as follows: \n",
    "\n",
    "Take a model with parameter $s$ (e.g. the Ridge with tuning parameter `alpha`): \n",
    "\n",
    "1. divide the data into $K$ roughly equal parts ($K = 5$ or $K = 10$)\n",
    "\n",
    "1. for each $k \\in \\{1, 2,..., K\\}$ fit the model with parameter $s$ to the other $K-1$ parts and compute its error $E_k(s)$  in predicting the $k$-th part.\n",
    "\n",
    "1. the overall cross-validation error is then $CV(s)= \\frac{1}{K} \\sum_{k=1}^K E_k(s)$. \n",
    "\n",
    "1. do this for many values of $s$ and choose the value of s that minimize $CV (s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6627e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:55:20.775724Z",
     "iopub.status.busy": "2024-11-07T16:55:20.775336Z",
     "iopub.status.idle": "2024-11-07T16:55:20.800342Z",
     "shell.execute_reply": "2024-11-07T16:55:20.799680Z"
    }
   },
   "outputs": [],
   "source": [
    "alphas = np.exp(np.arange(np.log(10), np.log(10001), (np.log(10000) - np.log(10)) / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f12747-040f-4be5-9676-527dc3066a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:55:20.802810Z",
     "iopub.status.busy": "2024-11-07T16:55:20.802521Z",
     "iopub.status.idle": "2024-11-07T16:55:20.827388Z",
     "shell.execute_reply": "2024-11-07T16:55:20.826853Z"
    }
   },
   "outputs": [],
   "source": [
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d599c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:55:20.829640Z",
     "iopub.status.busy": "2024-11-07T16:55:20.829182Z",
     "iopub.status.idle": "2024-11-07T16:56:00.280695Z",
     "shell.execute_reply": "2024-11-07T16:56:00.279931Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = make_pipeline(\n",
    "    StandardScaler(with_mean=False),\n",
    "    PolynomialFeatures(degree=2),\n",
    "    RidgeCV(alphas=alphas, cv=5),\n",
    "    MeanVariance(),\n",
    ")\n",
    "\n",
    "m = Backtester(estimator).compute_holdings(features, target).compute_pnl(ret)\n",
    "line(m.pnl_, cumsum=True, title=\"RidgeCV with polynomial features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a0dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:00.283474Z",
     "iopub.status.busy": "2024-11-07T16:56:00.282931Z",
     "iopub.status.idle": "2024-11-07T16:56:00.423792Z",
     "shell.execute_reply": "2024-11-07T16:56:00.423166Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    pd.Series([m[2].alpha_ for m in m.estimators_]),\n",
    "    title=\"Cross-validated alphas\",\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eec7e9",
   "metadata": {},
   "source": [
    "In this example, the fitted alphas over rolling windows are not very stable (probably given the small rolling windows used here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313aae4",
   "metadata": {},
   "source": [
    "## Random parameter search for Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a688cc",
   "metadata": {},
   "source": [
    "We first compute a `Lightgbm` benchmark with the fixed baseline parameters used in a previous section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c1c90-e65c-4fd3-90c4-c2cb35e5ea5f",
   "metadata": {},
   "source": [
    "Some resources on the parameters of `Lightgbm` can be found in its documentation: \n",
    "\n",
    "- https://lightgbm.readthedocs.io/en/latest/Parameters.html#learning-control-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b08f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:00.426506Z",
     "iopub.status.busy": "2024-11-07T16:56:00.426071Z",
     "iopub.status.idle": "2024-11-07T16:56:34.669506Z",
     "shell.execute_reply": "2024-11-07T16:56:34.668649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = make_pipeline(\n",
    "    MultiLGBMRegressor(min_child_samples=5, n_estimators=25), MeanVariance()\n",
    ")\n",
    "\n",
    "pnl_lgb = {\"fixed_params\": Backtester(estimator).train(features, target, ret)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20ea83",
   "metadata": {},
   "source": [
    "We now do a search with random parameters drawn from predetermined distributions: \n",
    "\n",
    "- the random parameter generators come from the `scipy.stats` module -- in particular `randint`, `uniform` and `loguniform`.\n",
    "- we use the `scikit-learn` function `ParameterSampler` as wrapper. \n",
    "\n",
    "Setup: \n",
    "\n",
    "- the objective is to maximize the sharpe ratio over the early period 1945 to 1972 (as the `train` period). \n",
    "- the evaluation is the performance of the backtest over the 1972-to-2000 period (as the `test` period). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381c6b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:34.672779Z",
     "iopub.status.busy": "2024-11-07T16:56:34.672284Z",
     "iopub.status.idle": "2024-11-07T16:56:34.992219Z",
     "shell.execute_reply": "2024-11-07T16:56:34.991637Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, randint, uniform\n",
    "from sklearn.model_selection import ParameterSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b3caa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:34.994618Z",
     "iopub.status.busy": "2024-11-07T16:56:34.994230Z",
     "iopub.status.idle": "2024-11-07T16:56:35.020288Z",
     "shell.execute_reply": "2024-11-07T16:56:35.019760Z"
    }
   },
   "outputs": [],
   "source": [
    "n_iter = 300\n",
    "start_date = \"1945-01-01\"\n",
    "end_date = \"1972-04-01\"\n",
    "param_distributions = {\n",
    "    \"max_depth\": randint(3, 10),\n",
    "    \"num_leaves\": randint(2, 2**8),\n",
    "    \"n_estimators\": randint(5, 50),\n",
    "    \"min_split_gain\": uniform(0, 1.0),\n",
    "    \"min_child_samples\": randint(1, 5),\n",
    "    \"reg_lambda\": loguniform(1e-8, 1.0),\n",
    "    \"reg_alpha\": loguniform(1e-8, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af5f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:35.022446Z",
     "iopub.status.busy": "2024-11-07T16:56:35.022060Z",
     "iopub.status.idle": "2024-11-07T16:56:35.051550Z",
     "shell.execute_reply": "2024-11-07T16:56:35.050946Z"
    }
   },
   "outputs": [],
   "source": [
    "force_recompute = False\n",
    "cache_dir = Path(os.getcwd()) / \"cache\"\n",
    "if not cache_dir.is_dir():\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "fname = cache_dir / \"hpo_lgb.parquet\"\n",
    "if (force_recompute) | (not fname.exists()):\n",
    "    results_ = {}\n",
    "    for i, prm in enumerate(\n",
    "        ParameterSampler(param_distributions=param_distributions, n_iter=n_iter)\n",
    "    ):\n",
    "        estimator = make_pipeline(LGBMRegressor(**prm), MeanVariance())\n",
    "        pnl_ = Backtester(estimator, end_date=end_date).train(features, target, ret)\n",
    "        prm.update({\"sr\": pnl_.pipe(sharpe_ratio)})\n",
    "        results_[i] = pd.Series(prm)\n",
    "    results = pd.DataFrame.from_dict(results_, orient=\"index\").sort_values(\"sr\")\n",
    "    results.to_parquet(fname)\n",
    "else:\n",
    "    results = pd.read_parquet(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544e316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:35.053851Z",
     "iopub.status.busy": "2024-11-07T16:56:35.053461Z",
     "iopub.status.idle": "2024-11-07T16:56:35.193510Z",
     "shell.execute_reply": "2024-11-07T16:56:35.192931Z"
    }
   },
   "outputs": [],
   "source": [
    "df = results.sort_index()[[\"sr\"]].assign(sr_cummax=lambda x: x.sr.cummax())\n",
    "line(df, title=\"Optimisation history: random search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92b752",
   "metadata": {},
   "source": [
    "Using the sharpe ratio statistics presented in a previous section, we can compute a standard error around the maximum sharpe ratio: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f3b111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:35.195902Z",
     "iopub.status.busy": "2024-11-07T16:56:35.195512Z",
     "iopub.status.idle": "2024-11-07T16:56:35.220863Z",
     "shell.execute_reply": "2024-11-07T16:56:35.220256Z"
    }
   },
   "outputs": [],
   "source": [
    "sr_max = results.iloc[-1][\"sr\"] / np.sqrt(12)\n",
    "sr_std = np.sqrt(12) * np.sqrt((1 + 0.5 * sr_max**2) / len(ret[start_date:end_date]))\n",
    "sr_range = results[\"sr\"].pipe(lambda x: x.max() - x.min())\n",
    "print(\n",
    "    f\"The sharpe ratio standard deviation at the maximum sharpe ratio (of {sr_max * np.sqrt(12):.2f}) is {sr_std:.2f}\"\n",
    ")\n",
    "\n",
    "print(f\"The range of the sharpe ratios in the random search is {sr_range:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db0185",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:35.223129Z",
     "iopub.status.busy": "2024-11-07T16:56:35.222662Z",
     "iopub.status.idle": "2024-11-07T16:56:35.246328Z",
     "shell.execute_reply": "2024-11-07T16:56:35.245779Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = results.drop(\"sr\", axis=1).iloc[-1].to_dict()\n",
    "best_params[\"num_leaves\"] = int(best_params[\"num_leaves\"])\n",
    "best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "best_params[\"min_child_samples\"] = int(best_params[\"min_child_samples\"])\n",
    "best_params[\"n_estimators\"] = int(best_params[\"n_estimators\"])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628a1ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:56:35.248467Z",
     "iopub.status.busy": "2024-11-07T16:56:35.248074Z",
     "iopub.status.idle": "2024-11-07T16:57:14.027509Z",
     "shell.execute_reply": "2024-11-07T16:57:14.026587Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = make_pipeline(MultiLGBMRegressor(**best_params), MeanVariance())\n",
    "\n",
    "\n",
    "pnl_lgb[\"best_params\"] = Backtester(estimator).train(features, target, ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb7282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:57:14.030519Z",
     "iopub.status.busy": "2024-11-07T16:57:14.030175Z",
     "iopub.status.idle": "2024-11-07T16:57:14.312312Z",
     "shell.execute_reply": "2024-11-07T16:57:14.311713Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    {k: v.loc[start_date:end_date] for k, v in pnl_lgb.items()},\n",
    "    cumsum=True,\n",
    "    title=\"Lightgbm search: in-sample\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62b63f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:57:14.314776Z",
     "iopub.status.busy": "2024-11-07T16:57:14.314358Z",
     "iopub.status.idle": "2024-11-07T16:57:14.588638Z",
     "shell.execute_reply": "2024-11-07T16:57:14.588055Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    {k: v.loc[end_date:] for k, v in pnl_lgb.items()},\n",
    "    cumsum=True,\n",
    "    title=\"Lightgbm search: out-of-sample\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf118025",
   "metadata": {},
   "source": [
    "What are the parameters that are correlated with the sharpe ratio? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa4639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:57:14.591207Z",
     "iopub.status.busy": "2024-11-07T16:57:14.590736Z",
     "iopub.status.idle": "2024-11-07T16:57:14.698598Z",
     "shell.execute_reply": "2024-11-07T16:57:14.698053Z"
    }
   },
   "outputs": [],
   "source": [
    "bar(\n",
    "    results.corr()[\"sr\"].mul(np.sqrt(n_iter)).drop(\"sr\"),\n",
    "    title=\"T-stat correlation param value / sharpe ratio\",\n",
    "    horizontal=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734823cb",
   "metadata": {},
   "source": [
    "To assess more precisely the impact of parameters on the sharpe ratio, we run a regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859dc1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:57:14.701124Z",
     "iopub.status.busy": "2024-11-07T16:57:14.700653Z",
     "iopub.status.idle": "2024-11-07T16:57:15.709670Z",
     "shell.execute_reply": "2024-11-07T16:57:15.708988Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels import api\n",
    "\n",
    "m = api.OLS(results[\"sr\"], api.add_constant(results.drop(\"sr\", axis=1))).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530ad9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T16:57:15.712345Z",
     "iopub.status.busy": "2024-11-07T16:57:15.712046Z",
     "iopub.status.idle": "2024-11-07T16:57:15.751401Z",
     "shell.execute_reply": "2024-11-07T16:57:15.750850Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
