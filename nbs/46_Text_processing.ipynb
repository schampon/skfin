{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb5aa87-4aab-42e5-b5e5-88d311ad4cf9",
   "metadata": {},
   "source": [
    "# Text Representation and Sentiment Analysis of FOMC Statements: From Bag-of-Words to Deep Learning Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcecd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:08.201520Z",
     "iopub.status.busy": "2025-09-29T15:54:08.201278Z",
     "iopub.status.idle": "2025-09-29T15:54:09.680554Z",
     "shell.execute_reply": "2025-09-29T15:54:09.679779Z"
    }
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skfin.plot import bar, line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d385211-59d6-4961-93ea-f454ad38f835",
   "metadata": {},
   "source": [
    "In the previous section, we focused only on the dates of Federal Open Market Committee (FOMC) statements. We now turn to the task of extracting information from these statements -- in particular by providing a vector representation of each document.\n",
    "\n",
    "Representations of text have evolved significantly over time, starting from simple approaches such as the bag of words model, which treats text as an unordered collection of words and relies on exogenous dictionaries to map words to features. This method, however, lacks context and semantic understanding.\n",
    "\n",
    "To address these limitations, sparse representations like Term Frequency-Inverse Document Frequency (TF-IDF) were developed, which weigh words based on their importance across documents. These sparse matrices can be transformed into dense representations using techniques like Principal Component Analysis (PCA), Non-negative Matrix Factorization (NMF), or k-means clustering, improving efficiency and interpretability. \n",
    "\n",
    "More recently, advances in natural language processing have led to the emergence of dense representations through encoder transformer language models, such as BERT and GPT. These models capture deep contextual and semantic information by encoding words in multiple dimensions, revolutionizing how text is understood and processed in computational linguistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ef8f6",
   "metadata": {},
   "source": [
    "## Loading the FOMC statements "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31a4ba-3cd1-435a-a7fe-bdc018bf3e62",
   "metadata": {},
   "source": [
    "As discussed in the previous section, the FOMC statements can be loaded with the function `load_fomc_statements` and inspected with the function `show_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a34fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:09.683143Z",
     "iopub.status.busy": "2025-09-29T15:54:09.682760Z",
     "iopub.status.idle": "2025-09-29T15:54:09.947201Z",
     "shell.execute_reply": "2025-09-29T15:54:09.946464Z"
    }
   },
   "outputs": [],
   "source": [
    "from skfin.datasets_ import load_fomc_statements\n",
    "from skfin.text import show_text, plot_document_embeddings, plot_word_embeddings\n",
    "\n",
    "statements = load_fomc_statements(force_reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad4bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:09.949535Z",
     "iopub.status.busy": "2025-09-29T15:54:09.949145Z",
     "iopub.status.idle": "2025-09-29T15:54:09.975525Z",
     "shell.execute_reply": "2025-09-29T15:54:09.974929Z"
    }
   },
   "outputs": [],
   "source": [
    "special_days = [\"2008-01-22\", \"2010-05-09\", \"2020-03-15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bb53f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:09.977394Z",
     "iopub.status.busy": "2025-09-29T15:54:09.977161Z",
     "iopub.status.idle": "2025-09-29T15:54:10.011051Z",
     "shell.execute_reply": "2025-09-29T15:54:10.010426Z"
    }
   },
   "outputs": [],
   "source": [
    "show_text(statements.loc[special_days], n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66473262-0d39-4f43-a8e1-01e5daccc8db",
   "metadata": {},
   "source": [
    "## Bag of words: Sentiment in FOMC statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff15e5d-a6ee-4567-9af5-e663f8ee6d46",
   "metadata": {},
   "source": [
    "In this section, we measure sentiment with the Loughran-McDonalds sentiment dictionary in two ways: \n",
    "\n",
    "- sentiment = (#positive - #negative)/(#positive + #negative)\n",
    "- sentiment = (#positive - #negative)/(#words)\n",
    "\n",
    "In the first case, short documents (with few or no sentiment words) might lead to biased estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7865038-2dfc-4a9d-bf93-220678089999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.013070Z",
     "iopub.status.busy": "2025-09-29T15:54:10.012816Z",
     "iopub.status.idle": "2025-09-29T15:54:10.047931Z",
     "shell.execute_reply": "2025-09-29T15:54:10.047350Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skfin.datasets_ import load_fomc_statements, load_loughran_mcdonald_dictionary\n",
    "from skfin.plot import line\n",
    "from skfin.text import coefs_plot, show_text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6dd8f9-8097-46f3-af87-af0e372fef39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.049740Z",
     "iopub.status.busy": "2025-09-29T15:54:10.049510Z",
     "iopub.status.idle": "2025-09-29T15:54:10.226998Z",
     "shell.execute_reply": "2025-09-29T15:54:10.226235Z"
    }
   },
   "outputs": [],
   "source": [
    "statements = load_fomc_statements()\n",
    "lm = load_loughran_mcdonald_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449b9dd-701c-4011-8f6b-59495322db79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.229187Z",
     "iopub.status.busy": "2025-09-29T15:54:10.228902Z",
     "iopub.status.idle": "2025-09-29T15:54:10.255473Z",
     "shell.execute_reply": "2025-09-29T15:54:10.254889Z"
    }
   },
   "outputs": [],
   "source": [
    "X = statements[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1aff1e-9f2d-4310-aff2-b93076ba2919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.257242Z",
     "iopub.status.busy": "2025-09-29T15:54:10.257021Z",
     "iopub.status.idle": "2025-09-29T15:54:10.552543Z",
     "shell.execute_reply": "2025-09-29T15:54:10.551787Z"
    }
   },
   "outputs": [],
   "source": [
    "funcs = {\n",
    "    \"negative\": lambda x: x.Negative > 0,\n",
    "    \"positive\": lambda x: x.Positive > 0,\n",
    "    \"all\": lambda x: x.Word.notna(),\n",
    "}\n",
    "\n",
    "\n",
    "def get_total_count(X, lm, func):\n",
    "    m = CountVectorizer(vocabulary=lm.loc[func].Word.str.lower().values)\n",
    "    return pd.DataFrame(m.fit_transform(X).toarray(), index=X.index).sum(axis=1)\n",
    "\n",
    "\n",
    "lm_counts = pd.concat({k: get_total_count(X, lm, v) for k, v in funcs.items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0c0fa-a7ea-49fa-a860-2bd9e5858360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.554814Z",
     "iopub.status.busy": "2025-09-29T15:54:10.554513Z",
     "iopub.status.idle": "2025-09-29T15:54:10.784042Z",
     "shell.execute_reply": "2025-09-29T15:54:10.783412Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    lm_counts.pipe(lambda x: (x.positive - x.negative) / (x.positive + x.negative))\n",
    "    .resample(\"B\")\n",
    "    .last()\n",
    "    .ffill(),\n",
    "    legend=False,\n",
    "    title=\"Sentiment=(pos - neg)/(pos + neg) in FOMC statements\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4756a-d1e3-45eb-ab6b-5eae3f2105fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.785961Z",
     "iopub.status.busy": "2025-09-29T15:54:10.785708Z",
     "iopub.status.idle": "2025-09-29T15:54:10.986468Z",
     "shell.execute_reply": "2025-09-29T15:54:10.985849Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    lm_counts.pipe(lambda x: (x.positive - x.negative) / x[\"all\"])\n",
    "    .resample(\"B\")\n",
    "    .last()\n",
    "    .ffill(),\n",
    "    legend=False,\n",
    "    title=\"Sentiment=(pos - neg)/(all) in FOMC statements\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997d3df-1648-43ee-ac4c-67cd95309f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:10.988401Z",
     "iopub.status.busy": "2025-09-29T15:54:10.988151Z",
     "iopub.status.idle": "2025-09-29T15:54:11.024922Z",
     "shell.execute_reply": "2025-09-29T15:54:11.024361Z"
    }
   },
   "outputs": [],
   "source": [
    "lm_lexica = {\n",
    "    \"negative\": pd.Series(1, lm.loc[lm.Negative > 0].Word.str.lower().values),\n",
    "    \"positive\": pd.Series(1, lm.loc[lm.Positive > 0].Word.str.lower().values),\n",
    "}\n",
    "show_text(\n",
    "    statements.loc[[\"2000-12-19\", \"2013-12-18\", \"2014-01-29\"]], lexica=lm_lexica, n=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081d997-83ff-46c4-998e-73bbe883a1bb",
   "metadata": {},
   "source": [
    "## Sparse text representation: TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acc61e-e0b1-4e6e-a7ca-ab08f0f6abe6",
   "metadata": {},
   "source": [
    "The progress of Natural Language Processing has been based on coming up with progressively better representations of text. In this section, we first discuss \"word counting\" in a given corpus and then embedding derived from pretrained language models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7145d90",
   "metadata": {},
   "source": [
    "In order to extract features from text, the simplest way is to count words. In `scikit-learn`, this is done with the function `CountVectorizer`. A slightly more advanced feature is to select words based on a `TFIDF` score, defined as the product of the term frequency (`TF`) and the inverse document frequency (`IDF`). More precisely, the `TFIDF` score trades off: \n",
    "- the terms that are frequent and therefore important in a corpus: \n",
    "- the terms that appear in almost all documents and therefore are not helping to discriminate across documents. \n",
    "\n",
    "In `TfidfVectorizer`, terms can be filtered additionally with: \n",
    "- a `stop word` list\n",
    "- min and max document frequencies or counts \n",
    "- some token pattern (e.g. that eliminates the short tokens). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5be80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.026811Z",
     "iopub.status.busy": "2025-09-29T15:54:11.026588Z",
     "iopub.status.idle": "2025-09-29T15:54:11.248385Z",
     "shell.execute_reply": "2025-09-29T15:54:11.247715Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f0409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.250464Z",
     "iopub.status.busy": "2025-09-29T15:54:11.250190Z",
     "iopub.status.idle": "2025-09-29T15:54:11.370557Z",
     "shell.execute_reply": "2025-09-29T15:54:11.369880Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 3),\n",
    "    token_pattern=r\"\\b[a-zA-Z]{3,}\\b\",\n",
    ")\n",
    "X_ = vectorizer.fit_transform(statements[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf78da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.372623Z",
     "iopub.status.busy": "2025-09-29T15:54:11.372354Z",
     "iopub.status.idle": "2025-09-29T15:54:11.402124Z",
     "shell.execute_reply": "2025-09-29T15:54:11.401663Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = vectorizer.get_feature_names_out()\n",
    "print(len(cols))\n",
    "list(cols)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c50e34-af84-42c4-89a9-8ba309dc021b",
   "metadata": {},
   "source": [
    "In what follows, to reduce the impact over large  `tfidf` coefficients, we use the log transformationl $x \\mapsto log(1+x)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7f16c-f47d-4097-94c3-df8021e4fbb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.403834Z",
     "iopub.status.busy": "2025-09-29T15:54:11.403613Z",
     "iopub.status.idle": "2025-09-29T15:54:11.444316Z",
     "shell.execute_reply": "2025-09-29T15:54:11.443840Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tfidf = pd.DataFrame(\n",
    "    np.log1p(X_.toarray()), index=statements[\"text\"].index, columns=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99baf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.446029Z",
     "iopub.status.busy": "2025-09-29T15:54:11.445811Z",
     "iopub.status.idle": "2025-09-29T15:54:11.747806Z",
     "shell.execute_reply": "2025-09-29T15:54:11.747245Z"
    }
   },
   "outputs": [],
   "source": [
    "bar(\n",
    "    X_tfidf.mean().sort_values(ascending=False).head(30),\n",
    "    horizontal=True,\n",
    "    title=\"Largest (log1p) tfidf scores\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf56eff-98d2-4ebf-9e7a-b418bd8634f3",
   "metadata": {},
   "source": [
    "### Principal component exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b9875-7e47-4c8e-8164-8afa92687901",
   "metadata": {},
   "source": [
    "In terms of representation of text, one key feature of the `tfidf` representation is that it is very sparse (with many zeros). For the `tfidf` representation $X$ (where each row is a document and each column is an n-gram term out of the tfidf), the idea of a low-rank approximation is $\\hat{X}$ and $H$ such that $$ X \\approx \\hat{X} H^T, $$ \n",
    "\n",
    "where $\\hat{X}$ is a \"denser\" matrix than $X$ because intuitively, some columns have been combined. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9086f86-fb35-446e-a8d8-fdb2b7ba5703",
   "metadata": {},
   "source": [
    "We first perform Principal Component Analysis (`PCA`) using the singular-value decomposition (`svd`) function in `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb586060-d4a3-4bb1-93c7-67a041604e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:11.749879Z",
     "iopub.status.busy": "2025-09-29T15:54:11.749613Z",
     "iopub.status.idle": "2025-09-29T15:54:13.032873Z",
     "shell.execute_reply": "2025-09-29T15:54:13.032233Z"
    }
   },
   "outputs": [],
   "source": [
    "u, s, w = np.linalg.svd(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48fb633-efcb-4dd6-85d7-4a6e8052379e",
   "metadata": {},
   "source": [
    "A singular value decomposition yields: $$X = U \\times Diag (s) \\times W^T, $$\n",
    "\n",
    "where $s$ is the vector of eigenvalues and $U$ and $W$ are the matrix of eigenvectors. For a number of modes $n$, define: $s_n$ the vector with the first (largest) $n$ eivenvalues; and $U_n$ and $W_n$ the first $n$ columns of $U$ and $W$. \n",
    "\n",
    "Then with $\\hat{X} = U_n \\times Diag(\\sqrt{s_n})$ and $H_n =  W_n \\times Diag(\\sqrt{s_n})$, we have: \n",
    "\n",
    "$$X \\approx \\hat{X} H_n^T.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f0bbc-1661-47d8-be7f-787e91ef045c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:13.035203Z",
     "iopub.status.busy": "2025-09-29T15:54:13.034911Z",
     "iopub.status.idle": "2025-09-29T15:54:13.063668Z",
     "shell.execute_reply": "2025-09-29T15:54:13.063173Z"
    }
   },
   "outputs": [],
   "source": [
    "n_modes = 6\n",
    "\n",
    "signed_sqrt_eigv = np.diag(\n",
    "    np.sqrt(s[:n_modes]) * np.sign(np.mean(u[:, :n_modes], axis=0))\n",
    ")\n",
    "X_pca = pd.DataFrame(u[:, :n_modes].dot(signed_sqrt_eigv), index=statements.index)\n",
    "H_ = pd.DataFrame(w[:n_modes, :].T.dot(signed_sqrt_eigv), index=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af17740-d7e7-4e9f-b097-eccdae980f6d",
   "metadata": {},
   "source": [
    "We can compute a distance between the features $X$ and the approximation $\\hat{X}_n H_n^T$. More precisely, the Frobinus norm is the sum of squared coefficients of the matrix and it can be computed with `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b691dd-a8e7-4eb1-834c-be56018318ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:13.065567Z",
     "iopub.status.busy": "2025-09-29T15:54:13.065326Z",
     "iopub.status.idle": "2025-09-29T15:54:13.107220Z",
     "shell.execute_reply": "2025-09-29T15:54:13.106735Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_pca = scipy.linalg.norm(X_pca.dot(H_.T).sub(X_tfidf), ord=\"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b532c9-e28e-42af-a49a-faefdddf135c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:13.109123Z",
     "iopub.status.busy": "2025-09-29T15:54:13.108859Z",
     "iopub.status.idle": "2025-09-29T15:54:13.156603Z",
     "shell.execute_reply": "2025-09-29T15:54:13.155990Z"
    }
   },
   "outputs": [],
   "source": [
    "np.allclose(norm_pca, np.sqrt(X_pca.dot(H_.T).sub(X_tfidf).pow(2).sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238469f3-baf4-4bba-87f4-190cb9fac591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:13.158663Z",
     "iopub.status.busy": "2025-09-29T15:54:13.158356Z",
     "iopub.status.idle": "2025-09-29T15:54:13.939355Z",
     "shell.execute_reply": "2025-09-29T15:54:13.938804Z"
    }
   },
   "outputs": [],
   "source": [
    "def topbottom(x, n=5):\n",
    "    return pd.concat([x.nlargest(n=n), x.sort_values(ascending=False).tail(n)])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(int(n_modes / 2), 2, figsize=(20, 16))\n",
    "ax = ax.ravel()\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "for i in range(n_modes):\n",
    "    bar(H_[i].pipe(topbottom, n=5), horizontal=True, ax=ax[i], title=f\"PC {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7bc0c6-195f-42ef-a9e1-d6ccc2ea0ddc",
   "metadata": {},
   "source": [
    "The plot above shows that the first principal component `PC0` is related to the labor market and the second principal component `PC1` is relate to economic growth. The graph below shows the loadings on these factor over time by document. \n",
    "\n",
    "- in the earlier years (1999-2009), the statements talk more about economic growth (high loading on `PC1`, low loading on `PC0`), but there is a switch in later years (2010-2020). \n",
    "- interestingly the last part of the sample (2021-2023) are in the middle and do not seem well explained by the loadings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe33c7e-499d-453f-bc4d-5282fe770642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:13.941284Z",
     "iopub.status.busy": "2025-09-29T15:54:13.941012Z",
     "iopub.status.idle": "2025-09-29T15:54:14.473253Z",
     "shell.execute_reply": "2025-09-29T15:54:14.472729Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_document_embeddings(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7117b6-b328-4b71-9371-ec2e76670924",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1d68a-d755-4a83-a033-0df74ff7e250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:14.475157Z",
     "iopub.status.busy": "2025-09-29T15:54:14.474889Z",
     "iopub.status.idle": "2025-09-29T15:54:14.775590Z",
     "shell.execute_reply": "2025-09-29T15:54:14.774573Z"
    }
   },
   "outputs": [],
   "source": [
    "m = KMeans(n_clusters=6).fit(X_tfidf)\n",
    "X_kmeans = pd.get_dummies(pd.Series(m.labels_, index=statements.index))\n",
    "\n",
    "H3_ = pd.DataFrame(m.cluster_centers_.T, index=cols)\n",
    "norm_kmeans = scipy.linalg.norm(X_kmeans.dot(H3_.T).sub(X_tfidf), ord=\"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d009260-51d0-4106-b022-7b71acfe6ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:14.778249Z",
     "iopub.status.busy": "2025-09-29T15:54:14.777885Z",
     "iopub.status.idle": "2025-09-29T15:54:14.813273Z",
     "shell.execute_reply": "2025-09-29T15:54:14.812559Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The norm of the approximations are: pca = {norm_pca:.2f};  kmeans = {norm_kmeans:.2f}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc8c0d-b34c-486f-b1c7-9df6467f7e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:14.815579Z",
     "iopub.status.busy": "2025-09-29T15:54:14.814921Z",
     "iopub.status.idle": "2025-09-29T15:54:15.541101Z",
     "shell.execute_reply": "2025-09-29T15:54:15.540457Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_word_embeddings(H3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448449a-8adc-45df-83b2-c3451148cfaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:15.543161Z",
     "iopub.status.busy": "2025-09-29T15:54:15.542845Z",
     "iopub.status.idle": "2025-09-29T15:54:15.919468Z",
     "shell.execute_reply": "2025-09-29T15:54:15.918794Z"
    }
   },
   "outputs": [],
   "source": [
    "line(\n",
    "    X_kmeans.resample(\"B\").last().ffill(),\n",
    "    cumsum=True,\n",
    "    title=\"Cumulative topic loadings\",\n",
    "    legend_sharpe_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeda607-fa84-4f4c-828e-3cce05e6db00",
   "metadata": {},
   "source": [
    "Does the `sentence transformers` embeddings yield a decomposition which is less clustered in time? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb6b3a-e19a-49c4-a294-cb07c8aa079a",
   "metadata": {},
   "source": [
    "### Non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995ea26-280f-455d-b44b-50cf9a3329ec",
   "metadata": {},
   "source": [
    "It is often informative to group tokens into topics that explain differences across documents. A powerful algorithm is the non-negative matrix factorisation (`NMF`): for a non-negative matrix $X$ (such as the one with tfidf scores), `NMF` finds two other non-negative matrices such that $$ X \\approx \\hat{X}_n H_n^T. $$\n",
    "\n",
    "The number of topics (called `n_components` in the `scikit-learn` implementation) determines the number of columns in $X_n$ and the number of rows in $H_n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b11ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:15.921666Z",
     "iopub.status.busy": "2025-09-29T15:54:15.921320Z",
     "iopub.status.idle": "2025-09-29T15:54:16.098401Z",
     "shell.execute_reply": "2025-09-29T15:54:16.097648Z"
    }
   },
   "outputs": [],
   "source": [
    "n_components = 6\n",
    "m = NMF(\n",
    "    n_components=n_components,\n",
    "    init=\"nndsvd\",\n",
    "    solver=\"cd\",\n",
    "    beta_loss=\"frobenius\",\n",
    "    random_state=1,\n",
    "    alpha_W=0,\n",
    "    l1_ratio=0,\n",
    "    max_iter=500,\n",
    ").fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514dbcc2-00c8-4737-8aaa-8b9294b368cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:16.100697Z",
     "iopub.status.busy": "2025-09-29T15:54:16.100371Z",
     "iopub.status.idle": "2025-09-29T15:54:16.158484Z",
     "shell.execute_reply": "2025-09-29T15:54:16.157758Z"
    }
   },
   "outputs": [],
   "source": [
    "H2_ = pd.DataFrame(m.components_.T, index=cols)\n",
    "X_nmf = pd.DataFrame(m.transform(X_tfidf), index=statements.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9364f-2c63-4999-b9df-0215e42f3d3b",
   "metadata": {},
   "source": [
    "The non-negative matrix factorization provides a slightly better approximation as measured by the Frobinus norm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ac7ee-2fe0-4429-ab6c-160a2080d184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:16.160682Z",
     "iopub.status.busy": "2025-09-29T15:54:16.160340Z",
     "iopub.status.idle": "2025-09-29T15:54:16.201305Z",
     "shell.execute_reply": "2025-09-29T15:54:16.200591Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_nmf = scipy.linalg.norm(X_nmf.dot(H2_.T).sub(X_tfidf), ord=\"fro\")\n",
    "print(\n",
    "    f\"The norm of the approximations are: pca = {norm_pca:.2f}; ;  kmeans = {norm_kmeans:.2f}; nmf = {norm_nmf:.2f}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99780c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:16.203310Z",
     "iopub.status.busy": "2025-09-29T15:54:16.202987Z",
     "iopub.status.idle": "2025-09-29T15:54:16.934482Z",
     "shell.execute_reply": "2025-09-29T15:54:16.933839Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_word_embeddings(H2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f52ac7-79fe-4048-8bcc-0cbd49eaa1cc",
   "metadata": {},
   "source": [
    "Are these topics interesting? This is a matter of interpretation, but at least, the graph below shows that these topics capture a strong element of time-clustering which makes it a bit less useful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f963d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:16.936601Z",
     "iopub.status.busy": "2025-09-29T15:54:16.936277Z",
     "iopub.status.idle": "2025-09-29T15:54:17.521256Z",
     "shell.execute_reply": "2025-09-29T15:54:17.520599Z"
    }
   },
   "outputs": [],
   "source": [
    "line(X_nmf.resample(\"B\").last().ffill(), cumsum=True, title=\"Cumulative topic loadings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f813e-8457-4ee0-a615-e1eb71cdac6c",
   "metadata": {},
   "source": [
    "## Deep-learning embeddings: sentence transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c9eb7-caec-4fb1-bc03-f80481957593",
   "metadata": {},
   "source": [
    "Deep-learning models have been used heavily to power NLP applications, in particular with `transformers` architecture starting with Delvin et al. (2018): \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\". Sentence Transformers are language models fined-tuned from pretrained language models to specifically generate meaningful text representations (as embeddings). \n",
    "\n",
    "- https://www.sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71898b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:17.523431Z",
     "iopub.status.busy": "2025-09-29T15:54:17.523101Z",
     "iopub.status.idle": "2025-09-29T15:54:30.817216Z",
     "shell.execute_reply": "2025-09-29T15:54:30.816547Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ce3eb-fc70-4782-9a03-c5d7d9870ad1",
   "metadata": {},
   "source": [
    "We use here a specific pretrained model and use it to derive embeddings for the corpus of Fed statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4643a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:30.819696Z",
     "iopub.status.busy": "2025-09-29T15:54:30.819259Z",
     "iopub.status.idle": "2025-09-29T15:54:45.618750Z",
     "shell.execute_reply": "2025-09-29T15:54:45.618091Z"
    }
   },
   "outputs": [],
   "source": [
    "lm_name = \"all-distilroberta-v1\"\n",
    "m = SentenceTransformer(lm_name, device=\"cpu\", trust_remote_code=True)\n",
    "X_sbert = m.encode(statements[\"text\"].values, batch_size=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1cc44-21b4-4785-9594-5745052d61a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:45.621052Z",
     "iopub.status.busy": "2025-09-29T15:54:45.620769Z",
     "iopub.status.idle": "2025-09-29T15:54:46.069820Z",
     "shell.execute_reply": "2025-09-29T15:54:46.069260Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Model card:\\n - model name: {lm_name}\\n - number of parameters: {count_trainable_parameters(m) / 1e6:.1f}m\\n - embedding size: {m.get_sentence_embedding_dimension()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa2302-43a3-45ba-958b-ddbab21e416b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f420abc-c263-49f3-ae8f-f224b4aeaaf1",
   "metadata": {},
   "source": [
    "Uniform Manifold Approximation and Projection (UMAP)  is a non-linear dimensionality reduction technique. It works by constructing a high-dimensional graph representation of the data and then optimizing a low-dimensional graph to be as structurally similar as possible. UMAP is useful because it effectively preserves both local and global structures in the data, which makes it particularly good for visualizing clusters and relationships in high-dimensional datasets.\n",
    "\n",
    "- https://umap-learn.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6687f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:46.071794Z",
     "iopub.status.busy": "2025-09-29T15:54:46.071512Z",
     "iopub.status.idle": "2025-09-29T15:54:52.215720Z",
     "shell.execute_reply": "2025-09-29T15:54:52.215101Z"
    }
   },
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda429cc-fb00-4950-b4d0-c68d1d70b8ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:52.217897Z",
     "iopub.status.busy": "2025-09-29T15:54:52.217624Z",
     "iopub.status.idle": "2025-09-29T15:54:59.056292Z",
     "shell.execute_reply": "2025-09-29T15:54:59.055660Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_ = UMAP().fit_transform(X_tfidf)\n",
    "X_umap = pd.DataFrame(embedding_, index=statements.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a471c11-ae76-4738-a106-2b0a037ccaef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T15:54:59.058518Z",
     "iopub.status.busy": "2025-09-29T15:54:59.058237Z",
     "iopub.status.idle": "2025-09-29T15:55:00.333091Z",
     "shell.execute_reply": "2025-09-29T15:55:00.332522Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_document_embeddings(X_umap)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "skfin 2024",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1c07668c36c3453fbd55f8edd214d03d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38a1c1354490410ea8a27b39d2f33d23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "395847805d43401bb4b5067d6202e3d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a1e98177cdcf4eec9211279746a4edcf",
       "max": 114,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_634bd7316ec843a3a97008e4cf4a43ae",
       "tabbable": null,
       "tooltip": null,
       "value": 114
      }
     },
     "634bd7316ec843a3a97008e4cf4a43ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "89d77b05ffb24d24970ba4f08d730631": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d1c3a60141141a9880774b4148ff58f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a1e98177cdcf4eec9211279746a4edcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4344116d44b4cac8d73063c8e050d5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89d77b05ffb24d24970ba4f08d730631",
       "placeholder": "​",
       "style": "IPY_MODEL_d8464b8a42924a4e80d5802b2eb6f4f8",
       "tabbable": null,
       "tooltip": null,
       "value": "Batches: 100%"
      }
     },
     "d8464b8a42924a4e80d5802b2eb6f4f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e58f3716fdfb4f3a90ca0930c02a2387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_38a1c1354490410ea8a27b39d2f33d23",
       "placeholder": "​",
       "style": "IPY_MODEL_9d1c3a60141141a9880774b4148ff58f",
       "tabbable": null,
       "tooltip": null,
       "value": " 114/114 [00:10&lt;00:00, 22.82it/s]"
      }
     },
     "ef10ea349eb54423b70fd2b5238991a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c4344116d44b4cac8d73063c8e050d5e",
        "IPY_MODEL_395847805d43401bb4b5067d6202e3d7",
        "IPY_MODEL_e58f3716fdfb4f3a90ca0930c02a2387"
       ],
       "layout": "IPY_MODEL_1c07668c36c3453fbd55f8edd214d03d",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
