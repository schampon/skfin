{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Reversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we review the empirical evidence on `liquidity provision` and describe a  `mean-reversion` strategy on stock returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liquidity and autocorrelation of stock returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image('images/khandani_1.png',width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hedge funds as provider of liquidity:\n",
    "    \n",
    "-  trend perfected by Long-Term Capital Management (until its\n",
    "fatal crash in 1998...);\n",
    "\n",
    "> by taking long positions in stocks that have declined and short positions in stocks that have advanced over the previous\n",
    "day, the strategy actively provides liquidity to the marketplace;\n",
    "\n",
    "- this type of strategies generally requires a very high leverage, so anticipating market dislocations is key;\n",
    "\n",
    "- Khandani-Lo (2007) argue that hedge funds have overtook traditional market makers as liquidity providers, so much so\n",
    "that when hedge funds retract, the whole market collapses..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean-reversion (contrarian) strategy returns: holdings positive in past losers, negative in past\n",
    "winners: \n",
    "    \n",
    "$$h_{n, t} = - 1 \\times \\frac{1}{N} \\left(r_{n, t} - r_{\\text{Market}, t} \\right), $$\n",
    "\n",
    "where $r_{\\text{Market}, t} = \\frac{1}{N} \\sum_n r_{n, t}$ is the cross-sectional average. By construction, such a strategy would be cash-neutral: \n",
    "\n",
    "$$ \\sum_n h_{n, t} = 0.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khandani and Lo (2007):\n",
    "\n",
    "-  a market-making liquidity provision exhibits extreme losses during the week of August 6, 2007 – suggesting market-wide deleveraging.\n",
    "\n",
    "> We wish to acknowledge at the outset that the hypotheses advanced in this paper are speculative, tentative, and based solely on indirect evidence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image('images/khandaniLoFigure1.PNG',width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image('images/khandaniLoFigure2.PNG',width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image('images/khandaniLoTable1Header.PNG',width=500))\n",
    "display(Image('images/khandaniLoTable1.PNG',width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative Equity Funds Hit Hard In August 2007\n",
    "\n",
    "-  specifically, August 7th–9th, and massive reversal on August 10th\n",
    "- some of the most consistently profitable funds lost too\n",
    "- seemed to affect only quants\n",
    "-  no real market news\n",
    "\n",
    "Kandhani-Lo “Unwind hypothesis:\"\n",
    "- many quant funds use similar factor models\n",
    "- if one fund has to unwind a large position, that hurts other funds\n",
    "- this causes these other funds to sell as well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence of event:\n",
    "\n",
    "-  initial losses \"initiated by the rapid unwind of one or more sizeable quantitative equity market-neutral portfolios (likely the result of a force liquidation by a multi-strategy fund or proprietary desk, possibly due to a margin call or a risk reduction)\"\n",
    "- \"these initial losses put pressure on a broader set of long/short and long-only equity portfolios, causing further losses by triggering stop/loss and deleveraging policies\"\n",
    "- \"on Friday, August 10th, sharp reversals in all five strategies erased nearly all of the losses of the previous four days, returning portfolio values back to their levels on the morning of August 6th. Of course, this assumes that portfolio leverage did not change during this tumultuous week, which is an unlikely assumption given the enormous losses during the first few days.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "display(Image('images/brunnermeier_1.png',width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from skfin.datasets import load_sklearn_stock_returns\n",
    "ret = load_sklearn_stock_returns(cache_dir=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stock return is found in the `example` folder on `scikit-learn` github repository and contains returns from 2003 to 2008. Interestingly, it includes not only US companies, but also European (e.g. Total, SAP, Novartis, etc) and Japanese (Honda, Sony, Toyota) ones, but also companies that are no longer publically traded (e.g. Dell) or have been split (DuPont). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, removing firms that are no longer publicly traded would create a survival bias in the sample. More generally, it is important to make sure that the firms that would have been available for trading are dynamically included in the backtest sample and removed when there are no longer traded (or not liquid enough to be traded given transaction costs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-reversion strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.plot import line, bar\n",
    "from skfin.metrics import sharpe_ratio\n",
    "from skfin.mv_estimators import MeanVariance \n",
    "from skfin.backtesting import Backtester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than setting the positions as $-1 \\times$ returns (as Khandani and Lo do), we feed the $-1 \\times$ EMA(returns) into the `Backtester` class to get mean-variance positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_score(x, clip=5): \n",
    "    return x.sub(x.mean(axis=1), axis=0).div(x.std(axis=1), axis=0).clip(lower=-clip, upper=clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_X = lambda x: -1 * x.pipe(xs_score).ewm(halflife=5).mean().fillna(0).values\n",
    "transform_y = lambda x: x.shift(-1).fillna(0).values\n",
    "features = transform_X(ret)\n",
    "target = transform_y(ret) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the industry backtests (which were at the Monthly frequency), these mean-reversion backtests are at the (business) day frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret.equals(ret.resample('B').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backtest is setup so that the risk-model is computed over 3-months (=63 business days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model_window = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Backtester(MeanVariance(), ret, max_train_size=risk_model_window, start_date=\"2003-05-01\").train(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = {'no-shrinkage': m.h_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "m.pnl_.div(np.sqrt(risk_model_window)).hist(bins=30, ax=ax[0])\n",
    "ax[0].set_title('Normalized pnl histogram')\n",
    "line(m.pnl_, cumsum=True, start_date=\"2003-05-01\", title='Mean-reversion pnl', ax=ax[1], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below show the lead-lag sharpe ratio. The right graph shows the lag: the $0$ lag is the tradable lag with a sharpe ratio equal to 1.06 (as in the cumulative pnl graph above). Lagging trading by several business days (up to five) maintain sharpe ratio approximately constant. \n",
    "\n",
    "The left graph shows the \"lead\" sharpe ratios -- that is, the counterfactual of what the sharpe ratio would have been with future information. Given that the strategy is strong countrarian, this lead sharpe ratio is very negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "fig.suptitle('Lead-lag sharpe ratio')\n",
    "bar({i: m.h_.shift(1 + i).mul(ret).sum(axis=1).pipe(sharpe_ratio) \n",
    "     for i in range(-10, 0)}, sort=False, title='Lead (with future information)', ax=ax[0])\n",
    "\n",
    "bar({i: m.h_.shift(1 + i).mul(ret).sum(axis=1).pipe(sharpe_ratio) \n",
    "     for i in range(0, 10)}, sort=False, title='Lag', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ = Backtester(MeanVariance(), ret, max_train_size=risk_model_window, start_date=\"2003-05-01\")\n",
    "pnls_ = {}\n",
    "for clip in [2, 3, 4, 5]: \n",
    "    transform_X_ = lambda x: -1 * x.pipe(xs_score, clip=clip).ewm(halflife=5).mean().fillna(0).values\n",
    "    features_ = transform_X_(ret)\n",
    "    pnls_[f'clip={clip}'] = m_.train(features_, target).pnl_\n",
    "line(pnls_, cumsum=True, title='Robustness: return clipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-reversion with risk-model shrinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, risk-model shrinkage is more necessary and useful with more assets (e.g. many stocks versus few industries). We show how the shrinkage of the coveriance matrix helps reducing the over-realisation of risk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import ShrunkCovariance\n",
    "pnls_ = {}\n",
    "for shrinkage in [0, .001, .01, .1]: \n",
    "    transform_V_ = lambda x: ShrunkCovariance(shrinkage=shrinkage).fit(x).covariance_\n",
    "    pnls_[shrinkage] = Backtester(MeanVariance(transform_V=transform_V_), ret, max_train_size=risk_model_window, start_date=\"2003-05-01\").train(features, target).pnl_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "line(pnls_, cumsum=True, title='Pnl (constant risk)', loc='best', ax=ax[0])\n",
    "line(pd.concat(pnls_, axis=1).pipe(lambda x: x.div(x.std())), \n",
    "     cumsum=True, title='Pnl (constant risk + ex-post rescaling) ', loc='best', ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with no risk-model shrinkage, the over-realisation of risk is very significant. With some shrinkage, there are less pnl outliers -- as shown in the histogram below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnls_[0.01].div(np.sqrt(risk_model_window)).hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage of mean-reversion strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we discuss how we can increase the level of risk per unit of leverage by concentrating the positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkage = 0.01\n",
    "transform_V_ = lambda x: ShrunkCovariance(shrinkage=shrinkage).fit(x).covariance_\n",
    "m_ = Backtester(MeanVariance(transform_V=transform_V_), ret, max_train_size=risk_model_window, start_date=\"2003-05-01\")\\\n",
    "        .train(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs['shrinkage=0.01'] = m_.h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfin.metrics import sharpe_ratio\n",
    "leverage_scaling = lambda x: x.div(x.abs().sum(axis=1), axis=0)\n",
    "\n",
    "def risk_per_unit_of_leverage(h, ret, return_sharpe_ratio=False):\n",
    "    pnl = h.pipe(leverage_scaling).shift(1).mul(ret).sum(axis=1)\\\n",
    "            .loc[h.index]\n",
    "    if return_sharpe_ratio: \n",
    "        return {'std': pnl.std()*np.sqrt(252), 'sharpe_ratio': pnl.pipe(sharpe_ratio)}\n",
    "    else: \n",
    "        return pnl.std()*np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "def func(x, q): \n",
    "    return x.where(x.ge(x.quantile(q=q,axis=1), axis=0)|x.le(x.quantile(q=1-q,axis=1), axis=0), 0)\n",
    "\n",
    "class Concentrate(TransformerMixin): \n",
    "    def __init__(self, q=.75): \n",
    "        self.q=q if q>.5 else 1-q  \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, return_dataframe=False): \n",
    "        if not isinstance(X, pd.DataFrame): \n",
    "            X = pd.DataFrame(X)\n",
    "        df = func(X, q=self.q)\n",
    "        if return_dataframe: \n",
    "            return df\n",
    "        else: \n",
    "            return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= .75\n",
    "hs[f'shrinkage=0.01, concentration q={q}'] = m_.h_.pipe(func, q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar(pd.Series({k: risk_per_unit_of_leverage(v, ret) for k, v in hs.items()}), \n",
    "    horizontal=True, title='Annualized risk per unit of leverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({q: m_.h_.pipe(func, q=q).pipe(risk_per_unit_of_leverage, \n",
    "                                                           ret=ret, \n",
    "                                                           return_sharpe_ratio=True) \n",
    "                             for q in np.arange(.5, .95, .05)}, orient='index')\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5)) \n",
    "ax.scatter(df.iloc[:, 0], df.iloc[:, 1], s=5, c='tab:blue')\n",
    "ax.set_xlabel(df.columns[0])\n",
    "ax.set_ylabel(df.columns[1])\n",
    "ax.set_title('Sharpe ratio against (annualized) risk per unit of leverage: concentrated positions')\n",
    "for i, txt in enumerate(df.index):\n",
    "    ax.text(df.iloc[i, 0], df.iloc[i, 1], round(txt,3), fontsize=9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concentrating the predictor instead of the positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of applying the concentration operator on positions, we can also apply on the predictor. The results are similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for q in  np.arange(.5, .95, .05): \n",
    "    estimator = make_pipeline(Concentrate(q=q), MeanVariance(transform_V=transform_V_))\n",
    "    m2_ = Backtester(estimator, ret, max_train_size=risk_model_window, start_date=\"2003-05-01\")\\\n",
    "            .train(features, target)\n",
    "    res[q] = m2_.h_.pipe(risk_per_unit_of_leverage, ret=ret, return_sharpe_ratio=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res, orient='index')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5)) \n",
    "ax.scatter(df.iloc[:, 0], df.iloc[:, 1], s=5, c='tab:blue')\n",
    "ax.set_xlabel(df.columns[0])\n",
    "ax.set_ylabel(df.columns[1])\n",
    "ax.set_title('Sharpe ratio against (annualized) risk per unit of leverage: concentrated predictor')\n",
    "for i, txt in enumerate(df.index):\n",
    "    ax.text(df.iloc[i, 0], df.iloc[i, 1], round(txt,3), fontsize=9)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (skfin)",
   "language": "python",
   "name": "skfin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
